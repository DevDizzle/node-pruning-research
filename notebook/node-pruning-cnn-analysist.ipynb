{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Node Pruning and Stratified K-Fold Cross-Validation Experiment\n",
        "\n",
        "## Note: Please refer to the README for instructions on how to acquire the dataset and install dependencies.\n",
        "\n",
        "## Ensure the dataset is placed in the appropriate directory before running this notebook.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SaWT4leRXrGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training & Experiment"
      ],
      "metadata": {
        "id": "kTzPnc0mecCM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jz2v9bAHQqh"
      },
      "source": [
        "### Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wBIHQPJ2IWGP"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import logging\n",
        "import pickle\n",
        "import gc\n",
        "import warnings\n",
        "import psutil\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "\n",
        "# TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model, clone_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.metrics import AUC, Recall, Precision\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Scikit-learn utilities\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Other necessary libraries\n",
        "from PIL import Image\n",
        "import io\n",
        "import zipfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beptG8hwJBu1"
      },
      "source": [
        "### Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-uBkpImJU_I",
        "outputId": "b9b1eea1-3de1-4ca2-d4b2-ed4dcd788517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-76b571841d8d>:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv('/content/train-metadata.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of benign samples: 400666\n",
            "Number of malignant samples: 393\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training metadata\n",
        "train_df = pd.read_csv('/content/train-metadata.csv')\n",
        "\n",
        "# Define image directory\n",
        "image_dir = '/content/train-image/image'\n",
        "\n",
        "# Add file paths to the DataFrame\n",
        "train_df['filepath'] = train_df['isic_id'].apply(lambda x: f\"{image_dir}/{x}.jpg\")\n",
        "\n",
        "# Count the number of target (malignant) and benign records before rebalancing\n",
        "num_benign = len(train_df[train_df['target'] == 0])\n",
        "num_malignant = len(train_df[train_df['target'] == 1])\n",
        "\n",
        "print(f\"Number of benign samples: {num_benign}\")\n",
        "print(f\"Number of malignant samples: {num_malignant}\")\n",
        "\n",
        "# Balance the Dataset with Random Under Sampling (RUS)\n",
        "# Separate majority and minority classes\n",
        "benign_df = train_df[train_df['target'] == 0]\n",
        "malignant_df = train_df[train_df['target'] == 1]\n",
        "\n",
        "# Perform Random Under Sampling on the majority class\n",
        "benign_df_under = benign_df.sample(len(malignant_df), random_state=42)\n",
        "\n",
        "# Combine the undersampled majority class with the minority class\n",
        "balanced_df = pd.concat([benign_df_under, malignant_df])\n",
        "\n",
        "# Shuffle the dataset\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Model"
      ],
      "metadata": {
        "id": "xGcicTK-IKbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    # Load the ResNet50V2 model without the top layers\n",
        "    base_model = ResNet50V2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze all layers in the base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom layers on top\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(\n",
        "        units=128,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=l2(1e-5)\n",
        "    )(x)\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Build the complete model\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    # Store the base_model as an attribute of model for easy access\n",
        "    model.base_model = base_model\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),  # Initial learning rate\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            AUC(name='auc'),\n",
        "            Precision(name='precision'),\n",
        "            Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s3-Zi1KUZMaU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = build_model()\n",
        "\n",
        "# Print the model summary\n",
        "print(\"Model Summary:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w90V4pisVpEX",
        "outputId": "f8cf993f-9233-4495-b4d0-9e2901c2c8b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_pad (\u001b[38;5;33mZeroPadding2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m230\u001b[0m, \u001b[38;5;34m230\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m9,472\u001b[0m │ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pad (\u001b[38;5;33mZeroPadding2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv2_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,864\u001b[0m │ conv2_block1_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv2_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m16,384\u001b[0m │ conv2_block2_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,864\u001b[0m │ conv2_block2_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv2_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m16,384\u001b[0m │ conv2_block3_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,864\u001b[0m │ conv2_block3_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m16,640\u001b[0m │ conv2_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ conv2_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m32,768\u001b[0m │ conv3_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,456\u001b[0m │ conv3_block1_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │        \u001b[38;5;34m131,584\u001b[0m │ conv3_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv3_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m65,536\u001b[0m │ conv3_block2_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,456\u001b[0m │ conv3_block2_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv3_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m65,536\u001b[0m │ conv3_block3_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,456\u001b[0m │ conv3_block3_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv3_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m65,536\u001b[0m │ conv3_block4_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block4_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,456\u001b[0m │ conv3_block4_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv3_block4_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block4_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv3_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m66,048\u001b[0m │ conv3_block4_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ conv3_block4_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv3_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m131,072\u001b[0m │ conv4_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ conv4_block1_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │        \u001b[38;5;34m525,312\u001b[0m │ conv4_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m262,144\u001b[0m │ conv4_block2_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ conv4_block2_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m262,144\u001b[0m │ conv4_block3_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ conv4_block3_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m262,144\u001b[0m │ conv4_block4_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ conv4_block4_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block4_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block4_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m262,144\u001b[0m │ conv4_block5_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m589,824\u001b[0m │ conv4_block5_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block5_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv4_block5_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block5_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m262,144\u001b[0m │ conv4_block6_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m589,824\u001b[0m │ conv4_block6_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv4_block6_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv4_block5_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │        \u001b[38;5;34m263,168\u001b[0m │ conv4_block6_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ conv4_block6_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │          \u001b[38;5;34m4,096\u001b[0m │ conv4_block6_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │        \u001b[38;5;34m524,288\u001b[0m │ conv5_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block1_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_0_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m2,099,200\u001b[0m │ conv5_block1_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block1_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_0_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv5_block1_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m1,048,576\u001b[0m │ conv5_block2_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block2_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block2_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv5_block2_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_preact_bn    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_preact_relu  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_preact_b… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m1,048,576\u001b[0m │ conv5_block3_preact_r… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_1_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_pad        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block3_2_pad[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_bn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_2_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv5_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_3_conv       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │      \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block3_2_relu[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_out (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv5_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv5_block3_3_conv[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ post_bn                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │          \u001b[38;5;34m8,192\u001b[0m │ conv5_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ post_relu (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ post_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ post_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m262,272\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_pad (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pad (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pool1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block1_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block1_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv2_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2_block2_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block2_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block2_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv2_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2_block3_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block3_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2_block3_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ conv2_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ conv3_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block1_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ conv3_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block1_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv3_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block2_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block2_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block2_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv3_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block3_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block3_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block3_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv3_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block4_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block4_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block4_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv3_block4_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ conv3_block4_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │ conv4_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block1_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ conv4_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block1_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block2_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block2_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block2_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block3_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block3_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block3_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block4_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block4_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block4_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block4_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block4_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block5_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block5_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block5_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block5_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv4_block5_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block5_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block6_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block6_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block6_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv4_block6_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ conv4_block6_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block6_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │ conv5_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block1_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_0_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ conv5_block1_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block1_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv5_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ conv5_block2_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block2_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block2_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv5_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_preact_bn    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_preact_relu  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_preact_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ conv5_block3_preact_r… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_1_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_pad        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block3_2_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_bn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_2_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_3_conv       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv5_block3_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv5_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ post_bn                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ post_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ post_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ post_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,827,201\u001b[0m (90.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,827,201</span> (90.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,401\u001b[0m (1.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,401</span> (1.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Pruning within Repeated Stratified K-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "mpogBdGIIYnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# 1. Setup Logging and Suppress Warnings\n",
        "# -------------------\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename='training.log',\n",
        "    filemode='a',  # Append mode\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "\n",
        "# Suppress specific warnings if necessary\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
        "\n",
        "# -------------------\n",
        "# 2. Initialize Data Structures\n",
        "# -------------------\n",
        "\n",
        "# Assuming 'balanced_df' is defined elsewhere in your code\n",
        "X = balanced_df['filepath']\n",
        "y = balanced_df['target']\n",
        "\n",
        "# Parameters\n",
        "num_folds = 5        # Number of folds per repeat\n",
        "num_repeats = 5     # Number of repeats\n",
        "total_splits = num_folds * num_repeats\n",
        "\n",
        "# Initialize RepeatedStratifiedKFold\n",
        "rskf = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=42)\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results_list = []\n",
        "\n",
        "# -------------------\n",
        "# 3. Define Helper Functions\n",
        "# -------------------\n",
        "\n",
        "def print_memory_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    mem = process.memory_info().rss / (1024 ** 3)  # in GB\n",
        "    print(f\"Current memory usage: {mem:.2f} GB\")\n",
        "    logging.info(f\"Current memory usage: {mem:.2f} GB\")\n",
        "\n",
        "def drop_node_in_hidden_layer(model, node_index, original_weights):\n",
        "    \"\"\"\n",
        "    Sets the specified node's weights and bias in the first Dense layer to zero.\n",
        "    Modifies the model in-place.\n",
        "    \"\"\"\n",
        "    # Access the first Dense layer\n",
        "    hidden_dense_layer = None\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            hidden_dense_layer = layer\n",
        "            break\n",
        "    if hidden_dense_layer is None:\n",
        "        raise ValueError(\"No Dense layer found in the model.\")\n",
        "\n",
        "    # Save current weights and biases\n",
        "    weights, biases = hidden_dense_layer.get_weights()\n",
        "    original_weights['weights'] = weights.copy()\n",
        "    original_weights['biases'] = biases.copy()\n",
        "\n",
        "    # Zero out the specified node's weights and bias\n",
        "    weights[:, node_index] = 0\n",
        "    biases[node_index] = 0\n",
        "\n",
        "    # Set the modified weights and biases back to the layer\n",
        "    hidden_dense_layer.set_weights([weights, biases])\n",
        "\n",
        "def restore_original_weights(model, original_weights):\n",
        "    \"\"\"\n",
        "    Restores the original weights and biases to the first Dense layer.\n",
        "    \"\"\"\n",
        "    hidden_dense_layer = None\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            hidden_dense_layer = layer\n",
        "            break\n",
        "    if hidden_dense_layer is not None and original_weights:\n",
        "        hidden_dense_layer.set_weights([original_weights['weights'], original_weights['biases']])\n",
        "\n",
        "def prune_nodes(model, nodes_to_prune):\n",
        "    \"\"\"\n",
        "    Prunes the first Dense layer by setting weights of specified nodes to zero.\n",
        "    Modifies the model in-place.\n",
        "    \"\"\"\n",
        "    # Access the first Dense layer\n",
        "    hidden_dense_layer = None\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            hidden_dense_layer = layer\n",
        "            break\n",
        "    if hidden_dense_layer is None:\n",
        "        raise ValueError(\"No Dense layer found in the model.\")\n",
        "\n",
        "    # Get weights and biases\n",
        "    weights, biases = hidden_dense_layer.get_weights()\n",
        "\n",
        "    # Zero out weights and biases for the specified nodes\n",
        "    for node_idx in nodes_to_prune:\n",
        "        weights[:, node_idx] = 0  # Zero out all incoming weights for the node\n",
        "        biases[node_idx] = 0      # Zero out the node's bias\n",
        "\n",
        "    # Set the modified weights and biases back to the layer\n",
        "    hidden_dense_layer.set_weights([weights, biases])\n",
        "\n",
        "def prune_and_evaluate(model, nodes_to_prune, val_generator, strategy_name, fold):\n",
        "    \"\"\"\n",
        "    Prunes specified nodes, evaluates the model, and restores original weights.\n",
        "    \"\"\"\n",
        "    # Access the first Dense layer\n",
        "    hidden_dense_layer = None\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            hidden_dense_layer = layer\n",
        "            break\n",
        "\n",
        "    # Save original weights before pruning\n",
        "    original_weights = {}\n",
        "    weights, biases = hidden_dense_layer.get_weights()\n",
        "    original_weights['weights'] = weights.copy()\n",
        "    original_weights['biases'] = biases.copy()\n",
        "\n",
        "    # Prune the nodes\n",
        "    prune_nodes(model, nodes_to_prune)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = model.evaluate(val_generator, verbose=0)\n",
        "    pruned_loss, pruned_accuracy, pruned_auc, pruned_precision, pruned_recall = metrics\n",
        "\n",
        "    # Append the results\n",
        "    results_list.append({\n",
        "        'Fold': fold,\n",
        "        'Pruning_Strategy': strategy_name,\n",
        "        'Accuracy': pruned_accuracy,\n",
        "        'AUC': pruned_auc,\n",
        "        'Precision': pruned_precision,\n",
        "        'Recall': pruned_recall\n",
        "    })\n",
        "\n",
        "    # Restore original weights\n",
        "    restore_original_weights(model, original_weights)\n",
        "    del original_weights\n",
        "    gc.collect()\n",
        "\n",
        "# -------------------\n",
        "# 4. Training and Pruning Loop\n",
        "# -------------------\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(rskf.split(X, y), 1):\n",
        "    logging.info(f\"--- Fold {fold}/{total_splits} ---\")\n",
        "    print(f\"Starting Fold {fold}/{total_splits}\")\n",
        "    print_memory_usage()\n",
        "\n",
        "    try:\n",
        "        # Split data\n",
        "        train_data = balanced_df.iloc[train_idx].reset_index(drop=True)\n",
        "        val_data = balanced_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "        # Ensure 'target' column is of string type for data generators\n",
        "        train_data['target'] = train_data['target'].astype(str)\n",
        "        val_data['target'] = val_data['target'].astype(str)\n",
        "\n",
        "        # Data augmentation for training data\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=40,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "\n",
        "        # Data generator for validation data (no augmentation)\n",
        "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        # Create data generators\n",
        "        train_generator = train_datagen.flow_from_dataframe(\n",
        "            dataframe=train_data,\n",
        "            x_col='filepath',\n",
        "            y_col='target',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=16,  # Adjust as needed\n",
        "            class_mode='binary',\n",
        "            shuffle=True\n",
        "        )\n",
        "        val_generator = val_datagen.flow_from_dataframe(\n",
        "            dataframe=val_data,\n",
        "            x_col='filepath',\n",
        "            y_col='target',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=16,\n",
        "            class_mode='binary',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        print(\"Data generators created successfully.\")\n",
        "        logging.info(\"Data generators created successfully.\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Build the model\n",
        "        model = build_model()  # Ensure this function is defined elsewhere\n",
        "        print(\"Model built successfully.\")\n",
        "        logging.info(\"Model built successfully.\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Define callbacks to monitor recall\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            mode='min',\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        # Define reduce_lr callback\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=2,\n",
        "            min_lr=1e-7\n",
        "        )\n",
        "\n",
        "        # Compile the model with recall as a metric\n",
        "        model.compile(\n",
        "            optimizer=Adam(),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
        "        )\n",
        "\n",
        "        # Train the model (first stage)\n",
        "        logging.info(\"Starting initial training...\")\n",
        "        print(\"Starting initial training...\")\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            epochs=10,  # Adjust as needed\n",
        "            validation_data=val_generator,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=1  # Show progress\n",
        "        )\n",
        "        logging.info(\"Initial training completed.\")\n",
        "        print(\"Initial training completed.\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Ensure all base model layers are frozen\n",
        "        for layer in model.base_model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Ensure only custom layers are trainable\n",
        "        for layer in model.layers:\n",
        "            if layer.name in ['global_average_pooling2d', 'dense', 'dropout', 'dense_1']:\n",
        "                layer.trainable = True\n",
        "\n",
        "        # Recompile the model with a lower learning rate for fine-tuning\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=1e-6),  # Lower learning rate for fine-tuning\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
        "        )\n",
        "\n",
        "        # Fine-tune the model\n",
        "        logging.info(\"Starting fine-tuning...\")\n",
        "        print(\"Starting fine-tuning...\")\n",
        "        history_fine_tune = model.fit(\n",
        "            train_generator,\n",
        "            epochs=5,  # Fewer epochs for fine-tuning\n",
        "            validation_data=val_generator,\n",
        "            callbacks=[early_stopping, reduce_lr],\n",
        "            verbose=1  # Show progress\n",
        "        )\n",
        "        logging.info(\"Fine-tuning completed.\")\n",
        "        print(\"Fine-tuning completed.\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Evaluate the model\n",
        "        val_loss, val_accuracy, val_auc, val_precision, val_recall = model.evaluate(val_generator, verbose=0)\n",
        "        logging.info(f'Fold {fold} Validation Accuracy: {val_accuracy:.4f}')\n",
        "        logging.info(f'Fold {fold} Validation AUC: {val_auc:.4f}')\n",
        "        logging.info(f'Fold {fold} Validation Precision: {val_precision:.4f}')\n",
        "        logging.info(f'Fold {fold} Validation Recall: {val_recall:.4f}')\n",
        "        print(f'Fold {fold} Validation Accuracy: {val_accuracy:.4f}')\n",
        "        print(f'Fold {fold} Validation AUC: {val_auc:.4f}')\n",
        "        print(f'Fold {fold} Validation Precision: {val_precision:.4f}')\n",
        "        print(f'Fold {fold} Validation Recall: {val_recall:.4f}')\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Append the baseline performance metrics\n",
        "        results_list.append({\n",
        "            'Fold': fold,\n",
        "            'Pruning_Strategy': 'Baseline',\n",
        "            'Accuracy': val_accuracy,\n",
        "            'AUC': val_auc,\n",
        "            'Precision': val_precision,\n",
        "            'Recall': val_recall\n",
        "        })\n",
        "\n",
        "        # --- Node Pruning Steps ---\n",
        "\n",
        "        # Identify the first Dense layer\n",
        "        hidden_dense_layer = None\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Dense):\n",
        "                hidden_dense_layer = layer\n",
        "                break\n",
        "        if hidden_dense_layer is None:\n",
        "            logging.error(\"No Dense layer found in the model. Skipping pruning.\")\n",
        "            print(\"No Dense layer found in the model. Skipping pruning.\")\n",
        "            continue\n",
        "\n",
        "        num_nodes = hidden_dense_layer.units\n",
        "        logging.info(f\"Number of nodes in the first Dense layer: {num_nodes}\")\n",
        "        print(f\"Number of nodes in the first Dense layer: {num_nodes}\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Dictionaries to store Recall and Delta Recall for each node dropped\n",
        "        node_recall = {}\n",
        "        delta_recall = {}\n",
        "\n",
        "        logging.info(\"Starting node-dropping analysis...\")\n",
        "        print(\"Starting node-dropping analysis...\")\n",
        "        # Perform node-dropping analysis\n",
        "        for node_idx in tqdm(range(num_nodes), desc=\"Node Pruning\"):\n",
        "            original_weights = {}\n",
        "            # Drop the node\n",
        "            drop_node_in_hidden_layer(model, node_idx, original_weights)\n",
        "            # Evaluate the modified model\n",
        "            metrics = model.evaluate(val_generator, verbose=0)\n",
        "            val_loss_mod, val_accuracy_mod, val_auc_mod, val_precision_mod, val_recall_mod = metrics\n",
        "            node_recall[node_idx] = val_recall_mod\n",
        "            delta_recall[node_idx] = val_recall_mod - val_recall\n",
        "\n",
        "            # Restore the original weights\n",
        "            restore_original_weights(model, original_weights)\n",
        "            # Clean up\n",
        "            del original_weights\n",
        "            gc.collect()\n",
        "\n",
        "        # Identify nodes to remove based on significant recall improvement\n",
        "        threshold = 0.01  # Adjust as needed\n",
        "        nodes_to_remove = [node for node, delta in delta_recall.items() if delta > threshold]\n",
        "        logging.info(f\"Nodes to remove for improved Recall: {nodes_to_remove}\")\n",
        "        print(f\"Nodes to remove for improved Recall: {nodes_to_remove}\")\n",
        "        print_memory_usage()\n",
        "\n",
        "        # Prune and evaluate the model by removing nodes that significantly improved recall\n",
        "        prune_and_evaluate(model, nodes_to_remove, val_generator, 'Pruned_All', fold)\n",
        "        print_memory_usage()\n",
        "\n",
        "        # --- Further Pruning: Top 1, 5, 10, 15 Nodes ---\n",
        "\n",
        "        # Get sorted nodes based on delta_recall\n",
        "        sorted_nodes = sorted(delta_recall.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Define the top N values\n",
        "        top_N_values = [1, 5, 10, 15]\n",
        "\n",
        "        for N in top_N_values:\n",
        "            top_N_nodes = [node for node, delta in sorted_nodes[:N]]\n",
        "            logging.info(f\"Top {N} nodes to prune based on Recall improvement: {top_N_nodes}\")\n",
        "            print(f\"Top {N} nodes to prune based on Recall improvement: {top_N_nodes}\")\n",
        "            print_memory_usage()\n",
        "\n",
        "            # Prune and evaluate\n",
        "            strategy_name = f'Pruned_Top{N}'\n",
        "            prune_and_evaluate(model, top_N_nodes, val_generator, strategy_name, fold)\n",
        "            print_memory_usage()\n",
        "\n",
        "        # Clean up models and free memory\n",
        "        del model\n",
        "        K.clear_session()\n",
        "        gc.collect()\n",
        "        logging.info(f\"Completed Fold {fold}.\\n\")\n",
        "        print(f\"Completed Fold {fold}.\\n\")\n",
        "        print_memory_usage()\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in Fold {fold}: {e}\")\n",
        "        print(f\"Error in Fold {fold}: {e}\")\n",
        "        # Clean up partially created objects\n",
        "        if 'model' in locals():\n",
        "            del model\n",
        "        K.clear_session()\n",
        "        gc.collect()\n",
        "        continue  # Proceed to the next fold\n",
        "\n",
        "# -------------------\n",
        "# 5. Save Results to Disk\n",
        "# -------------------\n",
        "\n",
        "# Create the DataFrame from the results list\n",
        "results_df = pd.DataFrame(results_list)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('/content/performance_metrics.csv', index=False)\n",
        "logging.info(\"All performance metrics have been saved to '/content/performance_metrics.csv'.\")\n",
        "print(\"All performance metrics have been saved to '/content/performance_metrics.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yDL92yXIS8N",
        "outputId": "f85dd84d-a42d-4c45-87b5-e42d07d1cee1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Fold 1/25\n",
            "Current memory usage: 1.82 GB\n",
            "Found 628 validated image filenames belonging to 2 classes.\n",
            "Found 158 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 1.82 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 1.82 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 501ms/step - accuracy: 0.6047 - auc: 0.6421 - loss: 0.7225 - precision: 0.6008 - recall: 0.5596 - val_accuracy: 0.6772 - val_auc: 0.7879 - val_loss: 0.5978 - val_precision: 0.6429 - val_recall: 0.7975\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6793 - auc: 0.7611 - loss: 0.5886 - precision: 0.6695 - recall: 0.7784 - val_accuracy: 0.6646 - val_auc: 0.7991 - val_loss: 0.6386 - val_precision: 0.8421 - val_recall: 0.4051\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7335 - auc: 0.7771 - loss: 0.5759 - precision: 0.7732 - recall: 0.6730 - val_accuracy: 0.7278 - val_auc: 0.7999 - val_loss: 0.5628 - val_precision: 0.8000 - val_recall: 0.6076\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7493 - auc: 0.8035 - loss: 0.5515 - precision: 0.7452 - recall: 0.7621 - val_accuracy: 0.7278 - val_auc: 0.8084 - val_loss: 0.5527 - val_precision: 0.7812 - val_recall: 0.6329\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7037 - auc: 0.7735 - loss: 0.5721 - precision: 0.6978 - recall: 0.6915 - val_accuracy: 0.6772 - val_auc: 0.8110 - val_loss: 0.6512 - val_precision: 0.8889 - val_recall: 0.4051\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7458 - auc: 0.8246 - loss: 0.5122 - precision: 0.7767 - recall: 0.6917 - val_accuracy: 0.7025 - val_auc: 0.7915 - val_loss: 0.5826 - val_precision: 0.7000 - val_recall: 0.7089\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7310 - auc: 0.8305 - loss: 0.5032 - precision: 0.7591 - recall: 0.7002 - val_accuracy: 0.7152 - val_auc: 0.8101 - val_loss: 0.5640 - val_precision: 0.8036 - val_recall: 0.5696\n",
            "Initial training completed.\n",
            "Current memory usage: 3.31 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.7109 - auc: 0.7797 - loss: 0.5652 - precision: 0.7079 - recall: 0.7233 - val_accuracy: 0.7278 - val_auc: 0.8085 - val_loss: 0.5527 - val_precision: 0.7812 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7346 - auc: 0.8032 - loss: 0.5356 - precision: 0.7310 - recall: 0.7683 - val_accuracy: 0.7278 - val_auc: 0.8088 - val_loss: 0.5527 - val_precision: 0.7812 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7366 - auc: 0.8195 - loss: 0.5190 - precision: 0.7264 - recall: 0.7694 - val_accuracy: 0.7278 - val_auc: 0.8088 - val_loss: 0.5528 - val_precision: 0.7812 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 3.57 GB\n",
            "Fold 1 Validation Accuracy: 0.7278\n",
            "Fold 1 Validation AUC: 0.8085\n",
            "Fold 1 Validation Precision: 0.7812\n",
            "Fold 1 Validation Recall: 0.6329\n",
            "Current memory usage: 3.58 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 3.58 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [01:34<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [0, 16, 32, 34, 62, 64, 90, 95, 100, 104, 113, 116, 119, 124]\n",
            "Current memory usage: 3.62 GB\n",
            "Current memory usage: 3.63 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [62]\n",
            "Current memory usage: 3.63 GB\n",
            "Current memory usage: 3.63 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [62, 16, 64, 32, 95]\n",
            "Current memory usage: 3.63 GB\n",
            "Current memory usage: 3.63 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [62, 16, 64, 32, 95, 113, 124, 0, 34, 90]\n",
            "Current memory usage: 3.63 GB\n",
            "Current memory usage: 3.63 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [62, 16, 64, 32, 95, 113, 124, 0, 34, 90, 100, 104, 116, 119, 1]\n",
            "Current memory usage: 3.63 GB\n",
            "Current memory usage: 3.63 GB\n",
            "Completed Fold 1.\n",
            "\n",
            "Current memory usage: 3.63 GB\n",
            "Starting Fold 2/25\n",
            "Current memory usage: 3.63 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 3.63 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 3.64 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 484ms/step - accuracy: 0.5829 - auc: 0.5905 - loss: 0.7685 - precision: 0.5871 - recall: 0.5910 - val_accuracy: 0.6178 - val_auc: 0.8004 - val_loss: 0.7443 - val_precision: 0.9524 - val_recall: 0.2532\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6789 - auc: 0.7459 - loss: 0.6001 - precision: 0.6627 - recall: 0.6484 - val_accuracy: 0.6879 - val_auc: 0.7966 - val_loss: 0.5812 - val_precision: 0.8261 - val_recall: 0.4810\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.7300 - auc: 0.7775 - loss: 0.5722 - precision: 0.6997 - recall: 0.7742 - val_accuracy: 0.6879 - val_auc: 0.7747 - val_loss: 0.5680 - val_precision: 0.7778 - val_recall: 0.5316\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7039 - auc: 0.7781 - loss: 0.5605 - precision: 0.7200 - recall: 0.7004 - val_accuracy: 0.6815 - val_auc: 0.7640 - val_loss: 0.6152 - val_precision: 0.8718 - val_recall: 0.4304\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7159 - auc: 0.8071 - loss: 0.5347 - precision: 0.7673 - recall: 0.6297 - val_accuracy: 0.6943 - val_auc: 0.7869 - val_loss: 0.5549 - val_precision: 0.7925 - val_recall: 0.5316\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7476 - auc: 0.8288 - loss: 0.5091 - precision: 0.7358 - recall: 0.8091 - val_accuracy: 0.7070 - val_auc: 0.7760 - val_loss: 0.5473 - val_precision: 0.7619 - val_recall: 0.6076\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7155 - auc: 0.7921 - loss: 0.5737 - precision: 0.6976 - recall: 0.7376 - val_accuracy: 0.7197 - val_auc: 0.8102 - val_loss: 0.5890 - val_precision: 0.8723 - val_recall: 0.5190\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7192 - auc: 0.8111 - loss: 0.5223 - precision: 0.7316 - recall: 0.6762 - val_accuracy: 0.7325 - val_auc: 0.8096 - val_loss: 0.5374 - val_precision: 0.8136 - val_recall: 0.6076\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7507 - auc: 0.8261 - loss: 0.5247 - precision: 0.7946 - recall: 0.6957 - val_accuracy: 0.6879 - val_auc: 0.7991 - val_loss: 0.5862 - val_precision: 0.8409 - val_recall: 0.4684\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7410 - auc: 0.8270 - loss: 0.5066 - precision: 0.7532 - recall: 0.7456 - val_accuracy: 0.7197 - val_auc: 0.7941 - val_loss: 0.5635 - val_precision: 0.7966 - val_recall: 0.5949\n",
            "Initial training completed.\n",
            "Current memory usage: 4.25 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.7295 - auc: 0.7982 - loss: 0.5278 - precision: 0.7538 - recall: 0.6894 - val_accuracy: 0.7325 - val_auc: 0.8099 - val_loss: 0.5373 - val_precision: 0.8136 - val_recall: 0.6076 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7764 - auc: 0.8590 - loss: 0.4731 - precision: 0.8042 - recall: 0.7682 - val_accuracy: 0.7325 - val_auc: 0.8103 - val_loss: 0.5375 - val_precision: 0.8136 - val_recall: 0.6076 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7358 - auc: 0.8246 - loss: 0.5089 - precision: 0.7232 - recall: 0.7063 - val_accuracy: 0.7325 - val_auc: 0.8104 - val_loss: 0.5375 - val_precision: 0.8136 - val_recall: 0.6076 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7748 - auc: 0.8623 - loss: 0.4737 - precision: 0.7472 - recall: 0.7848 - val_accuracy: 0.7325 - val_auc: 0.8104 - val_loss: 0.5376 - val_precision: 0.8136 - val_recall: 0.6076 - learning_rate: 2.0000e-07\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 4.48 GB\n",
            "Fold 2 Validation Accuracy: 0.7325\n",
            "Fold 2 Validation AUC: 0.8099\n",
            "Fold 2 Validation Precision: 0.8136\n",
            "Fold 2 Validation Recall: 0.6076\n",
            "Current memory usage: 4.48 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 4.48 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [01:44<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [95, 106, 113]\n",
            "Current memory usage: 4.32 GB\n",
            "Current memory usage: 4.32 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [95]\n",
            "Current memory usage: 4.32 GB\n",
            "Current memory usage: 4.32 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [95, 106, 113, 0, 1]\n",
            "Current memory usage: 4.32 GB\n",
            "Current memory usage: 4.32 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [95, 106, 113, 0, 1, 2, 3, 4, 5, 6]\n",
            "Current memory usage: 4.32 GB\n",
            "Current memory usage: 4.32 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [95, 106, 113, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "Current memory usage: 4.32 GB\n",
            "Current memory usage: 4.32 GB\n",
            "Completed Fold 2.\n",
            "\n",
            "Current memory usage: 4.32 GB\n",
            "Starting Fold 3/25\n",
            "Current memory usage: 4.32 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 4.32 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 4.34 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 333ms/step - accuracy: 0.5824 - auc: 0.6333 - loss: 0.7349 - precision: 0.5577 - recall: 0.5175 - val_accuracy: 0.7834 - val_auc: 0.8678 - val_loss: 0.5098 - val_precision: 0.8082 - val_recall: 0.7468\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6287 - auc: 0.6911 - loss: 0.6409 - precision: 0.6544 - recall: 0.5639 - val_accuracy: 0.6624 - val_auc: 0.8571 - val_loss: 0.5922 - val_precision: 0.9333 - val_recall: 0.3544\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6926 - auc: 0.7696 - loss: 0.5770 - precision: 0.7516 - recall: 0.6206 - val_accuracy: 0.8025 - val_auc: 0.8664 - val_loss: 0.5115 - val_precision: 0.8636 - val_recall: 0.7215\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7367 - auc: 0.8138 - loss: 0.5384 - precision: 0.7537 - recall: 0.7196 - val_accuracy: 0.7389 - val_auc: 0.8644 - val_loss: 0.5118 - val_precision: 0.9130 - val_recall: 0.5316\n",
            "Initial training completed.\n",
            "Current memory usage: 4.73 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.6669 - auc: 0.7305 - loss: 0.6268 - precision: 0.6444 - recall: 0.7835 - val_accuracy: 0.7771 - val_auc: 0.8673 - val_loss: 0.5096 - val_precision: 0.8056 - val_recall: 0.7342 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6771 - auc: 0.7602 - loss: 0.6069 - precision: 0.6420 - recall: 0.8015 - val_accuracy: 0.7707 - val_auc: 0.8672 - val_loss: 0.5095 - val_precision: 0.8028 - val_recall: 0.7215 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6477 - auc: 0.7114 - loss: 0.6467 - precision: 0.6152 - recall: 0.7244 - val_accuracy: 0.7771 - val_auc: 0.8679 - val_loss: 0.5094 - val_precision: 0.8143 - val_recall: 0.7215 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6214 - auc: 0.6946 - loss: 0.6631 - precision: 0.6060 - recall: 0.6943 - val_accuracy: 0.7707 - val_auc: 0.8671 - val_loss: 0.5093 - val_precision: 0.8116 - val_recall: 0.7089 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6364 - auc: 0.7455 - loss: 0.6111 - precision: 0.6071 - recall: 0.7538 - val_accuracy: 0.7643 - val_auc: 0.8679 - val_loss: 0.5093 - val_precision: 0.8088 - val_recall: 0.6962 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 5.08 GB\n",
            "Fold 3 Validation Accuracy: 0.7643\n",
            "Fold 3 Validation AUC: 0.8679\n",
            "Fold 3 Validation Precision: 0.8088\n",
            "Fold 3 Validation Recall: 0.6962\n",
            "Current memory usage: 5.09 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 5.09 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [01:54<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [1, 17, 21, 22, 24, 25, 26, 38, 51, 54, 60, 70, 73, 77, 78, 87, 92, 94, 100, 104, 109, 111, 112, 113, 119, 124, 126]\n",
            "Current memory usage: 4.93 GB\n",
            "Current memory usage: 4.93 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [109]\n",
            "Current memory usage: 4.93 GB\n",
            "Current memory usage: 4.93 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [109, 1, 77, 54, 112]\n",
            "Current memory usage: 4.93 GB\n",
            "Current memory usage: 4.94 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [109, 1, 77, 54, 112, 126, 119, 21, 24, 25]\n",
            "Current memory usage: 4.94 GB\n",
            "Current memory usage: 4.95 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [109, 1, 77, 54, 112, 126, 119, 21, 24, 25, 70, 92, 94, 100, 104]\n",
            "Current memory usage: 4.95 GB\n",
            "Current memory usage: 4.95 GB\n",
            "Completed Fold 3.\n",
            "\n",
            "Current memory usage: 4.95 GB\n",
            "Starting Fold 4/25\n",
            "Current memory usage: 4.95 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 4.95 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 4.96 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 340ms/step - accuracy: 0.6149 - auc: 0.6545 - loss: 0.7365 - precision: 0.6479 - recall: 0.5929 - val_accuracy: 0.6943 - val_auc: 0.7891 - val_loss: 0.5634 - val_precision: 0.7778 - val_recall: 0.5385\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6769 - auc: 0.7521 - loss: 0.5995 - precision: 0.7203 - recall: 0.6271 - val_accuracy: 0.7070 - val_auc: 0.7839 - val_loss: 0.5501 - val_precision: 0.7500 - val_recall: 0.6154\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7136 - auc: 0.7875 - loss: 0.5643 - precision: 0.7243 - recall: 0.7322 - val_accuracy: 0.6752 - val_auc: 0.7898 - val_loss: 0.5726 - val_precision: 0.8000 - val_recall: 0.4615\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6885 - auc: 0.7865 - loss: 0.5438 - precision: 0.6905 - recall: 0.5882 - val_accuracy: 0.7006 - val_auc: 0.8011 - val_loss: 0.5451 - val_precision: 0.7818 - val_recall: 0.5513\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7530 - auc: 0.8336 - loss: 0.5102 - precision: 0.7822 - recall: 0.6991 - val_accuracy: 0.6879 - val_auc: 0.7900 - val_loss: 0.5480 - val_precision: 0.7302 - val_recall: 0.5897\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7665 - auc: 0.8222 - loss: 0.5234 - precision: 0.7828 - recall: 0.7319 - val_accuracy: 0.6815 - val_auc: 0.8005 - val_loss: 0.5335 - val_precision: 0.7414 - val_recall: 0.5513\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7130 - auc: 0.7808 - loss: 0.5515 - precision: 0.7245 - recall: 0.6555 - val_accuracy: 0.6943 - val_auc: 0.8141 - val_loss: 0.5287 - val_precision: 0.7778 - val_recall: 0.5385\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7661 - auc: 0.8507 - loss: 0.4890 - precision: 0.7941 - recall: 0.7668 - val_accuracy: 0.7006 - val_auc: 0.8058 - val_loss: 0.5313 - val_precision: 0.6867 - val_recall: 0.7308\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7134 - auc: 0.8093 - loss: 0.5319 - precision: 0.6998 - recall: 0.7707 - val_accuracy: 0.7134 - val_auc: 0.8049 - val_loss: 0.5340 - val_precision: 0.7797 - val_recall: 0.5897\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7605 - auc: 0.8329 - loss: 0.5031 - precision: 0.7720 - recall: 0.6944 - val_accuracy: 0.7261 - val_auc: 0.8137 - val_loss: 0.5240 - val_precision: 0.7059 - val_recall: 0.7692\n",
            "Initial training completed.\n",
            "Current memory usage: 5.35 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 332ms/step - accuracy: 0.7695 - auc: 0.8546 - loss: 0.4905 - precision: 0.7170 - recall: 0.8350 - val_accuracy: 0.7261 - val_auc: 0.8140 - val_loss: 0.5238 - val_precision: 0.7059 - val_recall: 0.7692 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7710 - auc: 0.8296 - loss: 0.5286 - precision: 0.7368 - recall: 0.8242 - val_accuracy: 0.7261 - val_auc: 0.8138 - val_loss: 0.5238 - val_precision: 0.7059 - val_recall: 0.7692 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7427 - auc: 0.8221 - loss: 0.5170 - precision: 0.7254 - recall: 0.7797 - val_accuracy: 0.7261 - val_auc: 0.8139 - val_loss: 0.5237 - val_precision: 0.7059 - val_recall: 0.7692 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7603 - auc: 0.8475 - loss: 0.5033 - precision: 0.7493 - recall: 0.7683 - val_accuracy: 0.7261 - val_auc: 0.8132 - val_loss: 0.5237 - val_precision: 0.7059 - val_recall: 0.7692 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7160 - auc: 0.8091 - loss: 0.5319 - precision: 0.7112 - recall: 0.7574 - val_accuracy: 0.7197 - val_auc: 0.8136 - val_loss: 0.5236 - val_precision: 0.7024 - val_recall: 0.7564 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 5.64 GB\n",
            "Fold 4 Validation Accuracy: 0.7197\n",
            "Fold 4 Validation AUC: 0.8136\n",
            "Fold 4 Validation Precision: 0.7024\n",
            "Fold 4 Validation Recall: 0.7564\n",
            "Current memory usage: 5.64 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 5.64 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [02:04<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [10, 30, 51, 61, 62, 63, 68, 74, 81, 85, 87, 96, 97, 118, 124]\n",
            "Current memory usage: 5.48 GB\n",
            "Current memory usage: 5.48 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [30]\n",
            "Current memory usage: 5.48 GB\n",
            "Current memory usage: 5.49 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [30, 10, 51, 61, 62]\n",
            "Current memory usage: 5.49 GB\n",
            "Current memory usage: 5.49 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [30, 10, 51, 61, 62, 63, 68, 74, 81, 85]\n",
            "Current memory usage: 5.49 GB\n",
            "Current memory usage: 5.49 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [30, 10, 51, 61, 62, 63, 68, 74, 81, 85, 87, 96, 97, 118, 124]\n",
            "Current memory usage: 5.49 GB\n",
            "Current memory usage: 5.49 GB\n",
            "Completed Fold 4.\n",
            "\n",
            "Current memory usage: 5.49 GB\n",
            "Starting Fold 5/25\n",
            "Current memory usage: 5.49 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 5.49 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 5.51 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 334ms/step - accuracy: 0.5496 - auc: 0.5865 - loss: 0.7735 - precision: 0.5620 - recall: 0.5689 - val_accuracy: 0.7580 - val_auc: 0.7941 - val_loss: 0.5572 - val_precision: 0.7857 - val_recall: 0.7051\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7224 - auc: 0.7824 - loss: 0.5672 - precision: 0.7049 - recall: 0.7482 - val_accuracy: 0.7261 - val_auc: 0.7819 - val_loss: 0.5732 - val_precision: 0.7011 - val_recall: 0.7821\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6405 - auc: 0.7062 - loss: 0.6388 - precision: 0.6466 - recall: 0.6668 - val_accuracy: 0.7197 - val_auc: 0.7865 - val_loss: 0.5708 - val_precision: 0.8542 - val_recall: 0.5256\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6967 - auc: 0.7902 - loss: 0.5452 - precision: 0.7246 - recall: 0.6091 - val_accuracy: 0.6879 - val_auc: 0.7639 - val_loss: 0.5878 - val_precision: 0.6883 - val_recall: 0.6795\n",
            "Initial training completed.\n",
            "Current memory usage: 5.89 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 334ms/step - accuracy: 0.7342 - auc: 0.8051 - loss: 0.5388 - precision: 0.7491 - recall: 0.7182 - val_accuracy: 0.7516 - val_auc: 0.7933 - val_loss: 0.5573 - val_precision: 0.7826 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7201 - auc: 0.7764 - loss: 0.5715 - precision: 0.7306 - recall: 0.7328 - val_accuracy: 0.7516 - val_auc: 0.7946 - val_loss: 0.5574 - val_precision: 0.7826 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7063 - auc: 0.7771 - loss: 0.5737 - precision: 0.7305 - recall: 0.6928 - val_accuracy: 0.7452 - val_auc: 0.7944 - val_loss: 0.5575 - val_precision: 0.7794 - val_recall: 0.6795 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 6.14 GB\n",
            "Fold 5 Validation Accuracy: 0.7516\n",
            "Fold 5 Validation AUC: 0.7933\n",
            "Fold 5 Validation Precision: 0.7826\n",
            "Fold 5 Validation Recall: 0.6923\n",
            "Current memory usage: 6.15 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 6.15 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [02:18<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [0, 2, 3, 11, 21, 32, 35, 52, 65, 70, 81, 85, 97, 99, 100, 107, 110, 112, 113, 117, 118, 124]\n",
            "Current memory usage: 6.05 GB\n",
            "Current memory usage: 6.05 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [32]\n",
            "Current memory usage: 6.05 GB\n",
            "Current memory usage: 6.05 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [32, 100, 3, 70, 117]\n",
            "Current memory usage: 6.05 GB\n",
            "Current memory usage: 6.05 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [32, 100, 3, 70, 117, 35, 99, 0, 2, 11]\n",
            "Current memory usage: 6.05 GB\n",
            "Current memory usage: 6.05 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [32, 100, 3, 70, 117, 35, 99, 0, 2, 11, 21, 52, 65, 81, 85]\n",
            "Current memory usage: 6.05 GB\n",
            "Current memory usage: 6.05 GB\n",
            "Completed Fold 5.\n",
            "\n",
            "Current memory usage: 6.06 GB\n",
            "Starting Fold 6/25\n",
            "Current memory usage: 6.06 GB\n",
            "Found 628 validated image filenames belonging to 2 classes.\n",
            "Found 158 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 6.06 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 6.07 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 333ms/step - accuracy: 0.5836 - auc: 0.6296 - loss: 0.7310 - precision: 0.5705 - recall: 0.5139 - val_accuracy: 0.7025 - val_auc: 0.7807 - val_loss: 0.5595 - val_precision: 0.7963 - val_recall: 0.5443\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6746 - auc: 0.7450 - loss: 0.6104 - precision: 0.6647 - recall: 0.6893 - val_accuracy: 0.7025 - val_auc: 0.7993 - val_loss: 0.5540 - val_precision: 0.6667 - val_recall: 0.8101\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7282 - auc: 0.7884 - loss: 0.5554 - precision: 0.7365 - recall: 0.6780 - val_accuracy: 0.6835 - val_auc: 0.7983 - val_loss: 0.5951 - val_precision: 0.8372 - val_recall: 0.4557\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7314 - auc: 0.7992 - loss: 0.5369 - precision: 0.7307 - recall: 0.6658 - val_accuracy: 0.6772 - val_auc: 0.7748 - val_loss: 0.5675 - val_precision: 0.7188 - val_recall: 0.5823\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7326 - auc: 0.8013 - loss: 0.5386 - precision: 0.7337 - recall: 0.7249 - val_accuracy: 0.7215 - val_auc: 0.7974 - val_loss: 0.5379 - val_precision: 0.7536 - val_recall: 0.6582\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7190 - auc: 0.7964 - loss: 0.5473 - precision: 0.7187 - recall: 0.7619 - val_accuracy: 0.7025 - val_auc: 0.8031 - val_loss: 0.5397 - val_precision: 0.7963 - val_recall: 0.5443\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7269 - auc: 0.8203 - loss: 0.5195 - precision: 0.7295 - recall: 0.6649 - val_accuracy: 0.6899 - val_auc: 0.7974 - val_loss: 0.5528 - val_precision: 0.7206 - val_recall: 0.6203\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7498 - auc: 0.8252 - loss: 0.5187 - precision: 0.7552 - recall: 0.7839 - val_accuracy: 0.7089 - val_auc: 0.8011 - val_loss: 0.5721 - val_precision: 0.8113 - val_recall: 0.5443\n",
            "Initial training completed.\n",
            "Current memory usage: 6.47 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 337ms/step - accuracy: 0.7375 - auc: 0.8157 - loss: 0.5304 - precision: 0.7261 - recall: 0.7933 - val_accuracy: 0.7215 - val_auc: 0.7975 - val_loss: 0.5378 - val_precision: 0.7536 - val_recall: 0.6582 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7277 - auc: 0.8165 - loss: 0.5285 - precision: 0.7105 - recall: 0.7737 - val_accuracy: 0.7152 - val_auc: 0.7979 - val_loss: 0.5378 - val_precision: 0.7500 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7302 - auc: 0.8158 - loss: 0.5274 - precision: 0.7232 - recall: 0.8041 - val_accuracy: 0.7152 - val_auc: 0.7981 - val_loss: 0.5378 - val_precision: 0.7500 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7509 - auc: 0.8340 - loss: 0.4961 - precision: 0.7861 - recall: 0.7674 - val_accuracy: 0.7152 - val_auc: 0.7977 - val_loss: 0.5378 - val_precision: 0.7500 - val_recall: 0.6456 - learning_rate: 2.0000e-07\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7439 - auc: 0.8259 - loss: 0.5153 - precision: 0.7398 - recall: 0.7912 - val_accuracy: 0.7152 - val_auc: 0.7976 - val_loss: 0.5378 - val_precision: 0.7500 - val_recall: 0.6456 - learning_rate: 2.0000e-07\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 6.80 GB\n",
            "Fold 6 Validation Accuracy: 0.7152\n",
            "Fold 6 Validation AUC: 0.7976\n",
            "Fold 6 Validation Precision: 0.7500\n",
            "Fold 6 Validation Recall: 0.6456\n",
            "Current memory usage: 6.80 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 6.80 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [02:24<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [2, 3, 21, 53, 63, 64, 83, 88, 93]\n",
            "Current memory usage: 6.63 GB\n",
            "Current memory usage: 6.64 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [21]\n",
            "Current memory usage: 6.64 GB\n",
            "Current memory usage: 6.64 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [21, 2, 3, 53, 63]\n",
            "Current memory usage: 6.64 GB\n",
            "Current memory usage: 6.64 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [21, 2, 3, 53, 63, 64, 83, 88, 93, 1]\n",
            "Current memory usage: 6.64 GB\n",
            "Current memory usage: 6.65 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [21, 2, 3, 53, 63, 64, 83, 88, 93, 1, 4, 5, 6, 7, 8]\n",
            "Current memory usage: 6.65 GB\n",
            "Current memory usage: 6.65 GB\n",
            "Completed Fold 6.\n",
            "\n",
            "Current memory usage: 6.65 GB\n",
            "Starting Fold 7/25\n",
            "Current memory usage: 6.65 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 6.65 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 6.66 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 339ms/step - accuracy: 0.5441 - auc: 0.6187 - loss: 0.8073 - precision: 0.5450 - recall: 0.5544 - val_accuracy: 0.6306 - val_auc: 0.7063 - val_loss: 0.6819 - val_precision: 0.8182 - val_recall: 0.3418\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.6994 - auc: 0.7565 - loss: 0.5845 - precision: 0.7509 - recall: 0.5610 - val_accuracy: 0.7006 - val_auc: 0.7404 - val_loss: 0.6007 - val_precision: 0.7353 - val_recall: 0.6329\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7772 - auc: 0.8439 - loss: 0.4865 - precision: 0.7863 - recall: 0.7472 - val_accuracy: 0.6433 - val_auc: 0.7378 - val_loss: 0.6239 - val_precision: 0.6353 - val_recall: 0.6835\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7194 - auc: 0.8128 - loss: 0.5435 - precision: 0.6984 - recall: 0.7415 - val_accuracy: 0.6943 - val_auc: 0.7231 - val_loss: 0.6382 - val_precision: 0.7246 - val_recall: 0.6329\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7240 - auc: 0.8116 - loss: 0.5199 - precision: 0.7370 - recall: 0.6982 - val_accuracy: 0.6433 - val_auc: 0.7396 - val_loss: 0.7259 - val_precision: 0.8286 - val_recall: 0.3671\n",
            "Initial training completed.\n",
            "Current memory usage: 6.97 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 330ms/step - accuracy: 0.7373 - auc: 0.8179 - loss: 0.5551 - precision: 0.6903 - recall: 0.8425 - val_accuracy: 0.7070 - val_auc: 0.7395 - val_loss: 0.6010 - val_precision: 0.7463 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6813 - auc: 0.7653 - loss: 0.5981 - precision: 0.6502 - recall: 0.7798 - val_accuracy: 0.7070 - val_auc: 0.7395 - val_loss: 0.6013 - val_precision: 0.7463 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6876 - auc: 0.7806 - loss: 0.5966 - precision: 0.6524 - recall: 0.7832 - val_accuracy: 0.7070 - val_auc: 0.7391 - val_loss: 0.6015 - val_precision: 0.7463 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 7.27 GB\n",
            "Fold 7 Validation Accuracy: 0.7070\n",
            "Fold 7 Validation AUC: 0.7395\n",
            "Fold 7 Validation Precision: 0.7463\n",
            "Fold 7 Validation Recall: 0.6329\n",
            "Current memory usage: 7.24 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 7.24 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [02:34<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [49, 55, 56, 69, 72, 76, 95, 106, 109, 118]\n",
            "Current memory usage: 7.19 GB\n",
            "Current memory usage: 7.20 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [69]\n",
            "Current memory usage: 7.20 GB\n",
            "Current memory usage: 7.20 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [69, 118, 49, 55, 56]\n",
            "Current memory usage: 7.20 GB\n",
            "Current memory usage: 7.20 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [69, 118, 49, 55, 56, 72, 76, 95, 106, 109]\n",
            "Current memory usage: 7.20 GB\n",
            "Current memory usage: 7.20 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [69, 118, 49, 55, 56, 72, 76, 95, 106, 109, 0, 1, 2, 4, 5]\n",
            "Current memory usage: 7.20 GB\n",
            "Current memory usage: 7.20 GB\n",
            "Completed Fold 7.\n",
            "\n",
            "Current memory usage: 7.20 GB\n",
            "Starting Fold 8/25\n",
            "Current memory usage: 7.20 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 7.20 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 7.22 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 335ms/step - accuracy: 0.5706 - auc: 0.6317 - loss: 0.7360 - precision: 0.5989 - recall: 0.5613 - val_accuracy: 0.6815 - val_auc: 0.8042 - val_loss: 0.5667 - val_precision: 0.7544 - val_recall: 0.5443\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6534 - auc: 0.7206 - loss: 0.6349 - precision: 0.6564 - recall: 0.5730 - val_accuracy: 0.7134 - val_auc: 0.8062 - val_loss: 0.5629 - val_precision: 0.6977 - val_recall: 0.7595\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6774 - auc: 0.7512 - loss: 0.6175 - precision: 0.6626 - recall: 0.7380 - val_accuracy: 0.6815 - val_auc: 0.7788 - val_loss: 0.5814 - val_precision: 0.6495 - val_recall: 0.7975\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7482 - auc: 0.8189 - loss: 0.5281 - precision: 0.7459 - recall: 0.7328 - val_accuracy: 0.7580 - val_auc: 0.8273 - val_loss: 0.5354 - val_precision: 0.7733 - val_recall: 0.7342\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7206 - auc: 0.7924 - loss: 0.5533 - precision: 0.7291 - recall: 0.6974 - val_accuracy: 0.6943 - val_auc: 0.7805 - val_loss: 0.5755 - val_precision: 0.7123 - val_recall: 0.6582\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7282 - auc: 0.8131 - loss: 0.5288 - precision: 0.7603 - recall: 0.7007 - val_accuracy: 0.7134 - val_auc: 0.8126 - val_loss: 0.5701 - val_precision: 0.8542 - val_recall: 0.5190\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7277 - auc: 0.7889 - loss: 0.5481 - precision: 0.7484 - recall: 0.6964 - val_accuracy: 0.7452 - val_auc: 0.8177 - val_loss: 0.5336 - val_precision: 0.8197 - val_recall: 0.6329\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7594 - auc: 0.8262 - loss: 0.5113 - precision: 0.7492 - recall: 0.7369 - val_accuracy: 0.7325 - val_auc: 0.8054 - val_loss: 0.5525 - val_precision: 0.7342 - val_recall: 0.7342\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7667 - auc: 0.8435 - loss: 0.4928 - precision: 0.7625 - recall: 0.8065 - val_accuracy: 0.7325 - val_auc: 0.8225 - val_loss: 0.5409 - val_precision: 0.7033 - val_recall: 0.8101\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7298 - auc: 0.8296 - loss: 0.5089 - precision: 0.7522 - recall: 0.7278 - val_accuracy: 0.7325 - val_auc: 0.7997 - val_loss: 0.5634 - val_precision: 0.7937 - val_recall: 0.6329\n",
            "Initial training completed.\n",
            "Current memory usage: 7.62 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 332ms/step - accuracy: 0.7098 - auc: 0.7968 - loss: 0.5434 - precision: 0.7379 - recall: 0.6609 - val_accuracy: 0.7389 - val_auc: 0.8174 - val_loss: 0.5335 - val_precision: 0.8065 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7571 - auc: 0.8295 - loss: 0.5059 - precision: 0.7559 - recall: 0.6871 - val_accuracy: 0.7389 - val_auc: 0.8177 - val_loss: 0.5334 - val_precision: 0.8065 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7026 - auc: 0.7996 - loss: 0.5487 - precision: 0.7310 - recall: 0.6303 - val_accuracy: 0.7389 - val_auc: 0.8177 - val_loss: 0.5332 - val_precision: 0.8065 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7504 - auc: 0.8336 - loss: 0.5095 - precision: 0.7860 - recall: 0.6812 - val_accuracy: 0.7389 - val_auc: 0.8182 - val_loss: 0.5331 - val_precision: 0.8065 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7280 - auc: 0.8207 - loss: 0.5212 - precision: 0.7812 - recall: 0.6589 - val_accuracy: 0.7389 - val_auc: 0.8181 - val_loss: 0.5331 - val_precision: 0.8065 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 7.93 GB\n",
            "Fold 8 Validation Accuracy: 0.7389\n",
            "Fold 8 Validation AUC: 0.8181\n",
            "Fold 8 Validation Precision: 0.8065\n",
            "Fold 8 Validation Recall: 0.6329\n",
            "Current memory usage: 7.83 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 7.83 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [02:48<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [0, 22, 27, 63, 69, 86, 87, 92, 94, 119]\n",
            "Current memory usage: 7.76 GB\n",
            "Current memory usage: 7.76 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [92]\n",
            "Current memory usage: 7.76 GB\n",
            "Current memory usage: 7.76 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [92, 63, 94, 0, 22]\n",
            "Current memory usage: 7.76 GB\n",
            "Current memory usage: 7.78 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [92, 63, 94, 0, 22, 27, 69, 86, 87, 119]\n",
            "Current memory usage: 7.78 GB\n",
            "Current memory usage: 7.78 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [92, 63, 94, 0, 22, 27, 69, 86, 87, 119, 1, 3, 4, 5, 6]\n",
            "Current memory usage: 7.78 GB\n",
            "Current memory usage: 7.78 GB\n",
            "Completed Fold 8.\n",
            "\n",
            "Current memory usage: 7.78 GB\n",
            "Starting Fold 9/25\n",
            "Current memory usage: 7.78 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 7.78 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 7.79 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 337ms/step - accuracy: 0.5664 - auc: 0.5941 - loss: 0.7628 - precision: 0.5680 - recall: 0.5323 - val_accuracy: 0.7006 - val_auc: 0.8126 - val_loss: 0.5571 - val_precision: 0.8444 - val_recall: 0.4872\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6932 - auc: 0.7797 - loss: 0.5683 - precision: 0.7204 - recall: 0.6355 - val_accuracy: 0.7389 - val_auc: 0.8029 - val_loss: 0.5514 - val_precision: 0.7403 - val_recall: 0.7308\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7089 - auc: 0.7800 - loss: 0.5731 - precision: 0.6867 - recall: 0.7698 - val_accuracy: 0.7134 - val_auc: 0.7928 - val_loss: 0.5556 - val_precision: 0.7895 - val_recall: 0.5769\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6859 - auc: 0.7556 - loss: 0.5894 - precision: 0.6741 - recall: 0.6471 - val_accuracy: 0.7325 - val_auc: 0.8135 - val_loss: 0.5294 - val_precision: 0.7571 - val_recall: 0.6795\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7327 - auc: 0.7978 - loss: 0.5495 - precision: 0.7659 - recall: 0.6875 - val_accuracy: 0.7134 - val_auc: 0.8156 - val_loss: 0.5385 - val_precision: 0.7463 - val_recall: 0.6410\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7669 - auc: 0.8268 - loss: 0.5017 - precision: 0.7921 - recall: 0.7507 - val_accuracy: 0.7325 - val_auc: 0.8164 - val_loss: 0.5280 - val_precision: 0.7500 - val_recall: 0.6923\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7361 - auc: 0.7632 - loss: 0.5718 - precision: 0.7521 - recall: 0.6636 - val_accuracy: 0.7325 - val_auc: 0.8204 - val_loss: 0.5315 - val_precision: 0.8103 - val_recall: 0.6026\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7544 - auc: 0.8460 - loss: 0.4869 - precision: 0.7465 - recall: 0.7649 - val_accuracy: 0.7325 - val_auc: 0.8136 - val_loss: 0.5353 - val_precision: 0.7250 - val_recall: 0.7436\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7125 - auc: 0.8019 - loss: 0.5340 - precision: 0.7001 - recall: 0.7481 - val_accuracy: 0.7197 - val_auc: 0.8094 - val_loss: 0.5621 - val_precision: 0.8148 - val_recall: 0.5641\n",
            "Initial training completed.\n",
            "Current memory usage: 8.18 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 329ms/step - accuracy: 0.7288 - auc: 0.8155 - loss: 0.5179 - precision: 0.7705 - recall: 0.6836 - val_accuracy: 0.7261 - val_auc: 0.8168 - val_loss: 0.5280 - val_precision: 0.7397 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7280 - auc: 0.8225 - loss: 0.5133 - precision: 0.7238 - recall: 0.6968 - val_accuracy: 0.7325 - val_auc: 0.8165 - val_loss: 0.5280 - val_precision: 0.7500 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7328 - auc: 0.8175 - loss: 0.5196 - precision: 0.7701 - recall: 0.6731 - val_accuracy: 0.7325 - val_auc: 0.8167 - val_loss: 0.5280 - val_precision: 0.7500 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 8.41 GB\n",
            "Fold 9 Validation Accuracy: 0.7261\n",
            "Fold 9 Validation AUC: 0.8168\n",
            "Fold 9 Validation Precision: 0.7397\n",
            "Fold 9 Validation Recall: 0.6923\n",
            "Current memory usage: 8.42 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 8.42 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [02:54<00:00,  1.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [28, 38, 44, 45, 47, 58, 59, 65, 66, 70, 72, 79, 84, 94, 96, 99]\n",
            "Current memory usage: 8.33 GB\n",
            "Current memory usage: 8.33 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [99]\n",
            "Current memory usage: 8.33 GB\n",
            "Current memory usage: 8.33 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [99, 96, 58, 79, 84]\n",
            "Current memory usage: 8.33 GB\n",
            "Current memory usage: 8.33 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [99, 96, 58, 79, 84, 28, 38, 44, 45, 47]\n",
            "Current memory usage: 8.33 GB\n",
            "Current memory usage: 8.33 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [99, 96, 58, 79, 84, 28, 38, 44, 45, 47, 59, 65, 66, 70, 72]\n",
            "Current memory usage: 8.33 GB\n",
            "Current memory usage: 8.33 GB\n",
            "Completed Fold 9.\n",
            "\n",
            "Current memory usage: 8.33 GB\n",
            "Starting Fold 10/25\n",
            "Current memory usage: 8.33 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 8.33 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 8.35 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 342ms/step - accuracy: 0.5471 - auc: 0.5837 - loss: 0.7904 - precision: 0.5477 - recall: 0.5695 - val_accuracy: 0.6242 - val_auc: 0.8470 - val_loss: 0.6323 - val_precision: 0.9524 - val_recall: 0.2564\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6564 - auc: 0.7319 - loss: 0.6262 - precision: 0.7184 - recall: 0.5088 - val_accuracy: 0.7898 - val_auc: 0.8685 - val_loss: 0.4956 - val_precision: 0.8571 - val_recall: 0.6923\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6866 - auc: 0.7560 - loss: 0.6001 - precision: 0.6883 - recall: 0.6762 - val_accuracy: 0.7580 - val_auc: 0.8642 - val_loss: 0.5240 - val_precision: 0.8846 - val_recall: 0.5897\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6771 - auc: 0.7746 - loss: 0.5739 - precision: 0.6890 - recall: 0.6067 - val_accuracy: 0.7134 - val_auc: 0.8550 - val_loss: 0.5363 - val_precision: 0.8837 - val_recall: 0.4872\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6813 - auc: 0.7513 - loss: 0.6215 - precision: 0.6648 - recall: 0.7058 - val_accuracy: 0.7006 - val_auc: 0.8546 - val_loss: 0.5776 - val_precision: 0.9697 - val_recall: 0.4103\n",
            "Initial training completed.\n",
            "Current memory usage: 8.75 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 336ms/step - accuracy: 0.7253 - auc: 0.8036 - loss: 0.5518 - precision: 0.7051 - recall: 0.8310 - val_accuracy: 0.7898 - val_auc: 0.8673 - val_loss: 0.4957 - val_precision: 0.8571 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7521 - auc: 0.8241 - loss: 0.5313 - precision: 0.7268 - recall: 0.8381 - val_accuracy: 0.7898 - val_auc: 0.8671 - val_loss: 0.4960 - val_precision: 0.8571 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6858 - auc: 0.7797 - loss: 0.5917 - precision: 0.6431 - recall: 0.8296 - val_accuracy: 0.7898 - val_auc: 0.8670 - val_loss: 0.4964 - val_precision: 0.8571 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 8.97 GB\n",
            "Fold 10 Validation Accuracy: 0.7898\n",
            "Fold 10 Validation AUC: 0.8673\n",
            "Fold 10 Validation Precision: 0.8571\n",
            "Fold 10 Validation Recall: 0.6923\n",
            "Current memory usage: 8.99 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 8.99 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [03:04<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [3, 15, 17, 19, 20, 35, 41, 49, 51, 57, 59, 60, 80, 83, 102, 107, 124]\n",
            "Current memory usage: 8.89 GB\n",
            "Current memory usage: 8.89 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [59]\n",
            "Current memory usage: 8.89 GB\n",
            "Current memory usage: 8.90 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [59, 49, 57, 80, 124]\n",
            "Current memory usage: 8.90 GB\n",
            "Current memory usage: 8.90 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [59, 49, 57, 80, 124, 3, 15, 17, 20, 51]\n",
            "Current memory usage: 8.90 GB\n",
            "Current memory usage: 8.90 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [59, 49, 57, 80, 124, 3, 15, 17, 20, 51, 102, 19, 35, 41, 60]\n",
            "Current memory usage: 8.90 GB\n",
            "Current memory usage: 8.90 GB\n",
            "Completed Fold 10.\n",
            "\n",
            "Current memory usage: 8.91 GB\n",
            "Starting Fold 11/25\n",
            "Current memory usage: 8.91 GB\n",
            "Found 628 validated image filenames belonging to 2 classes.\n",
            "Found 158 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 8.91 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 8.92 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 339ms/step - accuracy: 0.6242 - auc: 0.6677 - loss: 0.7130 - precision: 0.6409 - recall: 0.6633 - val_accuracy: 0.7215 - val_auc: 0.8290 - val_loss: 0.5434 - val_precision: 0.8431 - val_recall: 0.5443\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7182 - auc: 0.7740 - loss: 0.5834 - precision: 0.7697 - recall: 0.6623 - val_accuracy: 0.7278 - val_auc: 0.8306 - val_loss: 0.5132 - val_precision: 0.7903 - val_recall: 0.6203\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7217 - auc: 0.7851 - loss: 0.5643 - precision: 0.7368 - recall: 0.6469 - val_accuracy: 0.7405 - val_auc: 0.8335 - val_loss: 0.5150 - val_precision: 0.7159 - val_recall: 0.7975\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6851 - auc: 0.7895 - loss: 0.5681 - precision: 0.6578 - recall: 0.7257 - val_accuracy: 0.7342 - val_auc: 0.8295 - val_loss: 0.5211 - val_precision: 0.8364 - val_recall: 0.5823\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6988 - auc: 0.7913 - loss: 0.5574 - precision: 0.7625 - recall: 0.6201 - val_accuracy: 0.7468 - val_auc: 0.8398 - val_loss: 0.5110 - val_precision: 0.8545 - val_recall: 0.5949\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7228 - auc: 0.8042 - loss: 0.5377 - precision: 0.7201 - recall: 0.6870 - val_accuracy: 0.7405 - val_auc: 0.8237 - val_loss: 0.5083 - val_precision: 0.7969 - val_recall: 0.6456\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7251 - auc: 0.8165 - loss: 0.5291 - precision: 0.7694 - recall: 0.6682 - val_accuracy: 0.7089 - val_auc: 0.8141 - val_loss: 0.5536 - val_precision: 0.8235 - val_recall: 0.5316\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7328 - auc: 0.8146 - loss: 0.5344 - precision: 0.7520 - recall: 0.6715 - val_accuracy: 0.7152 - val_auc: 0.8236 - val_loss: 0.5372 - val_precision: 0.8400 - val_recall: 0.5316\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7356 - auc: 0.8185 - loss: 0.5225 - precision: 0.7702 - recall: 0.6721 - val_accuracy: 0.7532 - val_auc: 0.8305 - val_loss: 0.5317 - val_precision: 0.7174 - val_recall: 0.8354\n",
            "Initial training completed.\n",
            "Current memory usage: 9.32 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 335ms/step - accuracy: 0.6857 - auc: 0.7952 - loss: 0.5506 - precision: 0.7375 - recall: 0.6135 - val_accuracy: 0.7405 - val_auc: 0.8240 - val_loss: 0.5081 - val_precision: 0.7969 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7381 - auc: 0.8259 - loss: 0.5179 - precision: 0.7997 - recall: 0.6245 - val_accuracy: 0.7468 - val_auc: 0.8239 - val_loss: 0.5078 - val_precision: 0.8000 - val_recall: 0.6582 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7363 - auc: 0.7957 - loss: 0.5731 - precision: 0.7867 - recall: 0.6009 - val_accuracy: 0.7468 - val_auc: 0.8239 - val_loss: 0.5076 - val_precision: 0.7910 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6996 - auc: 0.7791 - loss: 0.5853 - precision: 0.7673 - recall: 0.5873 - val_accuracy: 0.7468 - val_auc: 0.8243 - val_loss: 0.5074 - val_precision: 0.7910 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7342 - auc: 0.7940 - loss: 0.5608 - precision: 0.8224 - recall: 0.5925 - val_accuracy: 0.7468 - val_auc: 0.8237 - val_loss: 0.5071 - val_precision: 0.7910 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 9.63 GB\n",
            "Fold 11 Validation Accuracy: 0.7468\n",
            "Fold 11 Validation AUC: 0.8237\n",
            "Fold 11 Validation Precision: 0.7910\n",
            "Fold 11 Validation Recall: 0.6709\n",
            "Current memory usage: 9.63 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 9.63 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [03:14<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [18, 19, 23, 79, 84, 89, 104, 109]\n",
            "Current memory usage: 9.46 GB\n",
            "Current memory usage: 9.46 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [23]\n",
            "Current memory usage: 9.46 GB\n",
            "Current memory usage: 9.46 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [23, 89, 18, 19, 79]\n",
            "Current memory usage: 9.46 GB\n",
            "Current memory usage: 9.46 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [23, 89, 18, 19, 79, 84, 104, 109, 0, 1]\n",
            "Current memory usage: 9.46 GB\n",
            "Current memory usage: 9.46 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [23, 89, 18, 19, 79, 84, 104, 109, 0, 1, 2, 3, 5, 6, 7]\n",
            "Current memory usage: 9.46 GB\n",
            "Current memory usage: 9.47 GB\n",
            "Completed Fold 11.\n",
            "\n",
            "Current memory usage: 9.47 GB\n",
            "Starting Fold 12/25\n",
            "Current memory usage: 9.47 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 9.47 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 9.48 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 333ms/step - accuracy: 0.5995 - auc: 0.6695 - loss: 0.6943 - precision: 0.5903 - recall: 0.5245 - val_accuracy: 0.6752 - val_auc: 0.7506 - val_loss: 0.5813 - val_precision: 0.6944 - val_recall: 0.6329\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7168 - auc: 0.7903 - loss: 0.5514 - precision: 0.7128 - recall: 0.7080 - val_accuracy: 0.6815 - val_auc: 0.7606 - val_loss: 0.6076 - val_precision: 0.8222 - val_recall: 0.4684\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7299 - auc: 0.7958 - loss: 0.5583 - precision: 0.7650 - recall: 0.6705 - val_accuracy: 0.6497 - val_auc: 0.7849 - val_loss: 0.6345 - val_precision: 0.8333 - val_recall: 0.3797\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7406 - auc: 0.8079 - loss: 0.5400 - precision: 0.7771 - recall: 0.6654 - val_accuracy: 0.7006 - val_auc: 0.7920 - val_loss: 0.5500 - val_precision: 0.7353 - val_recall: 0.6329\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7668 - auc: 0.8328 - loss: 0.5154 - precision: 0.7421 - recall: 0.7797 - val_accuracy: 0.6624 - val_auc: 0.7805 - val_loss: 0.5677 - val_precision: 0.7031 - val_recall: 0.5696\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7139 - auc: 0.7883 - loss: 0.5578 - precision: 0.7413 - recall: 0.6737 - val_accuracy: 0.6752 - val_auc: 0.7839 - val_loss: 0.5810 - val_precision: 0.7692 - val_recall: 0.5063\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7370 - auc: 0.8319 - loss: 0.5102 - precision: 0.7961 - recall: 0.6354 - val_accuracy: 0.6752 - val_auc: 0.7953 - val_loss: 0.5907 - val_precision: 0.7917 - val_recall: 0.4810\n",
            "Initial training completed.\n",
            "Current memory usage: 9.88 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 336ms/step - accuracy: 0.6997 - auc: 0.8107 - loss: 0.5298 - precision: 0.7092 - recall: 0.7018 - val_accuracy: 0.6943 - val_auc: 0.7924 - val_loss: 0.5500 - val_precision: 0.7313 - val_recall: 0.6203 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7512 - auc: 0.8144 - loss: 0.5270 - precision: 0.7403 - recall: 0.7677 - val_accuracy: 0.6943 - val_auc: 0.7928 - val_loss: 0.5501 - val_precision: 0.7313 - val_recall: 0.6203 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7457 - auc: 0.8350 - loss: 0.5062 - precision: 0.7412 - recall: 0.7621 - val_accuracy: 0.6943 - val_auc: 0.7928 - val_loss: 0.5501 - val_precision: 0.7313 - val_recall: 0.6203 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 10.11 GB\n",
            "Fold 12 Validation Accuracy: 0.6943\n",
            "Fold 12 Validation AUC: 0.7924\n",
            "Fold 12 Validation Precision: 0.7313\n",
            "Fold 12 Validation Recall: 0.6203\n",
            "Current memory usage: 10.12 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 10.12 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [03:24<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [0, 1, 4, 6, 7, 18, 20, 29, 40, 48, 49, 51, 55, 58, 66, 67, 69, 84, 89, 91, 92, 93, 100, 108, 113, 114, 116]\n",
            "Current memory usage: 10.05 GB\n",
            "Current memory usage: 10.05 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [114]\n",
            "Current memory usage: 10.05 GB\n",
            "Current memory usage: 10.05 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [114, 40, 4, 6, 20]\n",
            "Current memory usage: 10.05 GB\n",
            "Current memory usage: 10.05 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [114, 40, 4, 6, 20, 48, 91, 0, 1, 7]\n",
            "Current memory usage: 10.05 GB\n",
            "Current memory usage: 10.06 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [114, 40, 4, 6, 20, 48, 91, 0, 1, 7, 18, 29, 49, 51, 55]\n",
            "Current memory usage: 10.06 GB\n",
            "Current memory usage: 10.06 GB\n",
            "Completed Fold 12.\n",
            "\n",
            "Current memory usage: 10.06 GB\n",
            "Starting Fold 13/25\n",
            "Current memory usage: 10.06 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 10.06 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 10.07 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 337ms/step - accuracy: 0.5861 - auc: 0.6104 - loss: 0.7755 - precision: 0.5799 - recall: 0.5777 - val_accuracy: 0.7261 - val_auc: 0.7753 - val_loss: 0.5859 - val_precision: 0.7903 - val_recall: 0.6203\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.6862 - auc: 0.7446 - loss: 0.6081 - precision: 0.6948 - recall: 0.6948 - val_accuracy: 0.7325 - val_auc: 0.7838 - val_loss: 0.5868 - val_precision: 0.8627 - val_recall: 0.5570\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.6995 - auc: 0.7564 - loss: 0.5851 - precision: 0.7008 - recall: 0.6915 - val_accuracy: 0.7261 - val_auc: 0.7817 - val_loss: 0.5716 - val_precision: 0.7500 - val_recall: 0.6835\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7199 - auc: 0.7824 - loss: 0.5626 - precision: 0.7165 - recall: 0.7245 - val_accuracy: 0.7452 - val_auc: 0.7924 - val_loss: 0.5703 - val_precision: 0.8197 - val_recall: 0.6329\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7254 - auc: 0.8109 - loss: 0.5269 - precision: 0.7341 - recall: 0.7425 - val_accuracy: 0.6943 - val_auc: 0.7670 - val_loss: 0.6371 - val_precision: 0.8163 - val_recall: 0.5063\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7315 - auc: 0.8027 - loss: 0.5432 - precision: 0.7559 - recall: 0.6920 - val_accuracy: 0.7516 - val_auc: 0.7902 - val_loss: 0.5704 - val_precision: 0.7941 - val_recall: 0.6835\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7214 - auc: 0.8039 - loss: 0.5431 - precision: 0.7479 - recall: 0.6680 - val_accuracy: 0.7516 - val_auc: 0.7816 - val_loss: 0.5783 - val_precision: 0.7703 - val_recall: 0.7215\n",
            "Initial training completed.\n",
            "Current memory usage: 10.46 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 326ms/step - accuracy: 0.7106 - auc: 0.8069 - loss: 0.5428 - precision: 0.6924 - recall: 0.7866 - val_accuracy: 0.7452 - val_auc: 0.7920 - val_loss: 0.5706 - val_precision: 0.8197 - val_recall: 0.6329 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7571 - auc: 0.8413 - loss: 0.5141 - precision: 0.7197 - recall: 0.8064 - val_accuracy: 0.7389 - val_auc: 0.7918 - val_loss: 0.5709 - val_precision: 0.8167 - val_recall: 0.6203 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7377 - auc: 0.8222 - loss: 0.5231 - precision: 0.7497 - recall: 0.7333 - val_accuracy: 0.7389 - val_auc: 0.7919 - val_loss: 0.5711 - val_precision: 0.8167 - val_recall: 0.6203 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 10.69 GB\n",
            "Fold 13 Validation Accuracy: 0.7452\n",
            "Fold 13 Validation AUC: 0.7920\n",
            "Fold 13 Validation Precision: 0.8197\n",
            "Fold 13 Validation Recall: 0.6329\n",
            "Current memory usage: 10.71 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 10.71 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [03:34<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [16, 54, 65, 95]\n",
            "Current memory usage: 10.60 GB\n",
            "Current memory usage: 10.61 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [16]\n",
            "Current memory usage: 10.61 GB\n",
            "Current memory usage: 10.61 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [16, 54, 65, 95, 1]\n",
            "Current memory usage: 10.61 GB\n",
            "Current memory usage: 10.61 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [16, 54, 65, 95, 1, 3, 5, 6, 7, 8]\n",
            "Current memory usage: 10.61 GB\n",
            "Current memory usage: 10.61 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [16, 54, 65, 95, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
            "Current memory usage: 10.61 GB\n",
            "Current memory usage: 10.61 GB\n",
            "Completed Fold 13.\n",
            "\n",
            "Current memory usage: 10.61 GB\n",
            "Starting Fold 14/25\n",
            "Current memory usage: 10.61 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 10.61 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 10.62 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.5512 - auc: 0.5852 - loss: 0.7684 - precision: 0.5691 - recall: 0.5529 - val_accuracy: 0.6561 - val_auc: 0.7850 - val_loss: 0.5967 - val_precision: 0.8158 - val_recall: 0.3974\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7350 - auc: 0.8026 - loss: 0.5540 - precision: 0.7545 - recall: 0.7234 - val_accuracy: 0.6879 - val_auc: 0.8145 - val_loss: 0.5499 - val_precision: 0.7843 - val_recall: 0.5128\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6840 - auc: 0.7643 - loss: 0.5835 - precision: 0.7504 - recall: 0.6173 - val_accuracy: 0.6815 - val_auc: 0.8051 - val_loss: 0.5613 - val_precision: 0.8043 - val_recall: 0.4744\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7015 - auc: 0.7579 - loss: 0.6030 - precision: 0.7313 - recall: 0.6449 - val_accuracy: 0.6497 - val_auc: 0.7778 - val_loss: 0.5944 - val_precision: 0.7347 - val_recall: 0.4615\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7317 - auc: 0.7945 - loss: 0.5369 - precision: 0.7484 - recall: 0.6955 - val_accuracy: 0.6752 - val_auc: 0.8084 - val_loss: 0.5564 - val_precision: 0.8293 - val_recall: 0.4359\n",
            "Initial training completed.\n",
            "Current memory usage: 11.02 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 333ms/step - accuracy: 0.7064 - auc: 0.7738 - loss: 0.5753 - precision: 0.8098 - recall: 0.5776 - val_accuracy: 0.6943 - val_auc: 0.8143 - val_loss: 0.5495 - val_precision: 0.7885 - val_recall: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6824 - auc: 0.7697 - loss: 0.5693 - precision: 0.7207 - recall: 0.5784 - val_accuracy: 0.6943 - val_auc: 0.8141 - val_loss: 0.5493 - val_precision: 0.7885 - val_recall: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6763 - auc: 0.7646 - loss: 0.5964 - precision: 0.7484 - recall: 0.5522 - val_accuracy: 0.6943 - val_auc: 0.8152 - val_loss: 0.5490 - val_precision: 0.7885 - val_recall: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7154 - auc: 0.7969 - loss: 0.5482 - precision: 0.7723 - recall: 0.6018 - val_accuracy: 0.6943 - val_auc: 0.8152 - val_loss: 0.5488 - val_precision: 0.7885 - val_recall: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.6606 - auc: 0.7601 - loss: 0.5843 - precision: 0.7343 - recall: 0.5131 - val_accuracy: 0.6943 - val_auc: 0.8152 - val_loss: 0.5486 - val_precision: 0.7885 - val_recall: 0.5256 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 11.36 GB\n",
            "Fold 14 Validation Accuracy: 0.6943\n",
            "Fold 14 Validation AUC: 0.8152\n",
            "Fold 14 Validation Precision: 0.7885\n",
            "Fold 14 Validation Recall: 0.5256\n",
            "Current memory usage: 11.36 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 11.36 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [03:43<00:00,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [0, 13, 14, 28, 32, 34, 60, 93, 94, 103, 105, 123]\n",
            "Current memory usage: 11.17 GB\n",
            "Current memory usage: 11.18 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [13]\n",
            "Current memory usage: 11.18 GB\n",
            "Current memory usage: 11.18 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [13, 32, 103, 0, 34]\n",
            "Current memory usage: 11.18 GB\n",
            "Current memory usage: 11.18 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [13, 32, 103, 0, 34, 105, 123, 14, 28, 60]\n",
            "Current memory usage: 11.18 GB\n",
            "Current memory usage: 11.18 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [13, 32, 103, 0, 34, 105, 123, 14, 28, 60, 93, 94, 1, 2, 3]\n",
            "Current memory usage: 11.18 GB\n",
            "Current memory usage: 11.18 GB\n",
            "Completed Fold 14.\n",
            "\n",
            "Current memory usage: 11.18 GB\n",
            "Starting Fold 15/25\n",
            "Current memory usage: 11.18 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 11.18 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 11.19 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 339ms/step - accuracy: 0.6116 - auc: 0.6538 - loss: 0.7307 - precision: 0.6120 - recall: 0.6011 - val_accuracy: 0.7070 - val_auc: 0.8150 - val_loss: 0.5850 - val_precision: 0.9211 - val_recall: 0.4487\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7141 - auc: 0.7570 - loss: 0.5788 - precision: 0.7143 - recall: 0.6697 - val_accuracy: 0.7261 - val_auc: 0.8241 - val_loss: 0.5461 - val_precision: 0.8431 - val_recall: 0.5513\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.6987 - auc: 0.7754 - loss: 0.5667 - precision: 0.7059 - recall: 0.6867 - val_accuracy: 0.7197 - val_auc: 0.8300 - val_loss: 0.5431 - val_precision: 0.8269 - val_recall: 0.5513\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7306 - auc: 0.8190 - loss: 0.5153 - precision: 0.7680 - recall: 0.6866 - val_accuracy: 0.6815 - val_auc: 0.8362 - val_loss: 0.5835 - val_precision: 0.8500 - val_recall: 0.4359\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7219 - auc: 0.8087 - loss: 0.5232 - precision: 0.7598 - recall: 0.6948 - val_accuracy: 0.7325 - val_auc: 0.8503 - val_loss: 0.5449 - val_precision: 0.8600 - val_recall: 0.5513\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7082 - auc: 0.7975 - loss: 0.5436 - precision: 0.7131 - recall: 0.6750 - val_accuracy: 0.7452 - val_auc: 0.8459 - val_loss: 0.5285 - val_precision: 0.8393 - val_recall: 0.6026\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7173 - auc: 0.7894 - loss: 0.5584 - precision: 0.7254 - recall: 0.7166 - val_accuracy: 0.7197 - val_auc: 0.8143 - val_loss: 0.5710 - val_precision: 0.8864 - val_recall: 0.5000\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step - accuracy: 0.7466 - auc: 0.8291 - loss: 0.5025 - precision: 0.7703 - recall: 0.7384 - val_accuracy: 0.6752 - val_auc: 0.8361 - val_loss: 0.6337 - val_precision: 0.8857 - val_recall: 0.3974\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6767 - auc: 0.7673 - loss: 0.5913 - precision: 0.7214 - recall: 0.5913 - val_accuracy: 0.7197 - val_auc: 0.7918 - val_loss: 0.5547 - val_precision: 0.7656 - val_recall: 0.6282\n",
            "Initial training completed.\n",
            "Current memory usage: 11.62 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 333ms/step - accuracy: 0.7407 - auc: 0.8265 - loss: 0.5136 - precision: 0.7728 - recall: 0.6956 - val_accuracy: 0.7452 - val_auc: 0.8459 - val_loss: 0.5285 - val_precision: 0.8393 - val_recall: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7521 - auc: 0.8122 - loss: 0.5321 - precision: 0.7516 - recall: 0.7363 - val_accuracy: 0.7516 - val_auc: 0.8461 - val_loss: 0.5285 - val_precision: 0.8421 - val_recall: 0.6154 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6994 - auc: 0.7946 - loss: 0.5339 - precision: 0.6922 - recall: 0.6576 - val_accuracy: 0.7452 - val_auc: 0.8461 - val_loss: 0.5286 - val_precision: 0.8393 - val_recall: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6985 - auc: 0.7920 - loss: 0.5501 - precision: 0.7283 - recall: 0.6781 - val_accuracy: 0.7452 - val_auc: 0.8461 - val_loss: 0.5286 - val_precision: 0.8393 - val_recall: 0.6026 - learning_rate: 2.0000e-07\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 11.93 GB\n",
            "Fold 15 Validation Accuracy: 0.7452\n",
            "Fold 15 Validation AUC: 0.8459\n",
            "Fold 15 Validation Precision: 0.8393\n",
            "Fold 15 Validation Recall: 0.6026\n",
            "Current memory usage: 11.93 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 11.93 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [03:53<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [18, 31, 36, 37, 49, 52, 55, 57, 75, 93, 105, 110, 112, 119, 121, 122, 123, 124, 125]\n",
            "Current memory usage: 11.75 GB\n",
            "Current memory usage: 11.75 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [18]\n",
            "Current memory usage: 11.75 GB\n",
            "Current memory usage: 11.75 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [18, 49, 55, 122, 125]\n",
            "Current memory usage: 11.75 GB\n",
            "Current memory usage: 11.75 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [18, 49, 55, 122, 125, 37, 52, 75, 93, 112]\n",
            "Current memory usage: 11.75 GB\n",
            "Current memory usage: 11.77 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [18, 49, 55, 122, 125, 37, 52, 75, 93, 112, 121, 123, 124, 31, 36]\n",
            "Current memory usage: 11.77 GB\n",
            "Current memory usage: 11.77 GB\n",
            "Completed Fold 15.\n",
            "\n",
            "Current memory usage: 11.77 GB\n",
            "Starting Fold 16/25\n",
            "Current memory usage: 11.77 GB\n",
            "Found 628 validated image filenames belonging to 2 classes.\n",
            "Found 158 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 11.77 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 11.78 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 345ms/step - accuracy: 0.5953 - auc: 0.6572 - loss: 0.7001 - precision: 0.5912 - recall: 0.5836 - val_accuracy: 0.6899 - val_auc: 0.7662 - val_loss: 0.5908 - val_precision: 0.7344 - val_recall: 0.5949\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6932 - auc: 0.7554 - loss: 0.5920 - precision: 0.7018 - recall: 0.6603 - val_accuracy: 0.6899 - val_auc: 0.7819 - val_loss: 0.5744 - val_precision: 0.6923 - val_recall: 0.6835\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7248 - auc: 0.8018 - loss: 0.5498 - precision: 0.7284 - recall: 0.7628 - val_accuracy: 0.6646 - val_auc: 0.7475 - val_loss: 0.6187 - val_precision: 0.7321 - val_recall: 0.5190\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7042 - auc: 0.7607 - loss: 0.5890 - precision: 0.7130 - recall: 0.6463 - val_accuracy: 0.7025 - val_auc: 0.7698 - val_loss: 0.5843 - val_precision: 0.7759 - val_recall: 0.5696\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7611 - auc: 0.8179 - loss: 0.5266 - precision: 0.7749 - recall: 0.7533 - val_accuracy: 0.6962 - val_auc: 0.7758 - val_loss: 0.5868 - val_precision: 0.7627 - val_recall: 0.5696\n",
            "Initial training completed.\n",
            "Current memory usage: 12.16 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 337ms/step - accuracy: 0.6624 - auc: 0.7897 - loss: 0.5807 - precision: 0.6243 - recall: 0.7984 - val_accuracy: 0.6899 - val_auc: 0.7827 - val_loss: 0.5739 - val_precision: 0.6923 - val_recall: 0.6835 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6564 - auc: 0.7858 - loss: 0.6021 - precision: 0.6099 - recall: 0.8553 - val_accuracy: 0.6899 - val_auc: 0.7832 - val_loss: 0.5734 - val_precision: 0.6923 - val_recall: 0.6835 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6621 - auc: 0.7857 - loss: 0.6269 - precision: 0.6060 - recall: 0.8302 - val_accuracy: 0.6899 - val_auc: 0.7825 - val_loss: 0.5729 - val_precision: 0.6923 - val_recall: 0.6835 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7006 - auc: 0.7914 - loss: 0.5736 - precision: 0.6578 - recall: 0.8186 - val_accuracy: 0.6835 - val_auc: 0.7828 - val_loss: 0.5726 - val_precision: 0.6883 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6971 - auc: 0.7961 - loss: 0.5710 - precision: 0.6615 - recall: 0.8647 - val_accuracy: 0.6835 - val_auc: 0.7830 - val_loss: 0.5721 - val_precision: 0.6883 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 12.48 GB\n",
            "Fold 16 Validation Accuracy: 0.6835\n",
            "Fold 16 Validation AUC: 0.7830\n",
            "Fold 16 Validation Precision: 0.6883\n",
            "Fold 16 Validation Recall: 0.6709\n",
            "Current memory usage: 12.48 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 12.48 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [04:03<00:00,  1.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [4, 11, 31, 34, 38, 47, 50, 58, 61, 68, 84, 90, 94, 97, 102, 125]\n",
            "Current memory usage: 12.30 GB\n",
            "Current memory usage: 12.31 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [58]\n",
            "Current memory usage: 12.31 GB\n",
            "Current memory usage: 12.31 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [58, 94, 61, 68, 4]\n",
            "Current memory usage: 12.31 GB\n",
            "Current memory usage: 12.31 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [58, 94, 61, 68, 4, 11, 31, 34, 38, 47]\n",
            "Current memory usage: 12.31 GB\n",
            "Current memory usage: 12.31 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [58, 94, 61, 68, 4, 11, 31, 34, 38, 47, 50, 84, 90, 97, 102]\n",
            "Current memory usage: 12.31 GB\n",
            "Current memory usage: 12.31 GB\n",
            "Completed Fold 16.\n",
            "\n",
            "Current memory usage: 12.31 GB\n",
            "Starting Fold 17/25\n",
            "Current memory usage: 12.31 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 12.31 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 12.33 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.6237 - auc: 0.6584 - loss: 0.7180 - precision: 0.6225 - recall: 0.6220 - val_accuracy: 0.7516 - val_auc: 0.8106 - val_loss: 0.5442 - val_precision: 0.9000 - val_recall: 0.5696\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6789 - auc: 0.7665 - loss: 0.6034 - precision: 0.7377 - recall: 0.6355 - val_accuracy: 0.7707 - val_auc: 0.8229 - val_loss: 0.5202 - val_precision: 0.7945 - val_recall: 0.7342\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6648 - auc: 0.7297 - loss: 0.6077 - precision: 0.6679 - recall: 0.6461 - val_accuracy: 0.7707 - val_auc: 0.8191 - val_loss: 0.5496 - val_precision: 0.9057 - val_recall: 0.6076\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7271 - auc: 0.7737 - loss: 0.5721 - precision: 0.7761 - recall: 0.6686 - val_accuracy: 0.7771 - val_auc: 0.8296 - val_loss: 0.5055 - val_precision: 0.8548 - val_recall: 0.6709\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6889 - auc: 0.7682 - loss: 0.5728 - precision: 0.6736 - recall: 0.6371 - val_accuracy: 0.7580 - val_auc: 0.8160 - val_loss: 0.5244 - val_precision: 0.8596 - val_recall: 0.6203\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7086 - auc: 0.7863 - loss: 0.5621 - precision: 0.7210 - recall: 0.6677 - val_accuracy: 0.7452 - val_auc: 0.8214 - val_loss: 0.5160 - val_precision: 0.7910 - val_recall: 0.6709\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7683 - auc: 0.8571 - loss: 0.4766 - precision: 0.7746 - recall: 0.7706 - val_accuracy: 0.7389 - val_auc: 0.8234 - val_loss: 0.5245 - val_precision: 0.8065 - val_recall: 0.6329\n",
            "Initial training completed.\n",
            "Current memory usage: 12.81 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 343ms/step - accuracy: 0.6884 - auc: 0.7857 - loss: 0.5571 - precision: 0.7072 - recall: 0.6212 - val_accuracy: 0.7771 - val_auc: 0.8296 - val_loss: 0.5055 - val_precision: 0.8548 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7550 - auc: 0.8356 - loss: 0.5113 - precision: 0.7582 - recall: 0.7126 - val_accuracy: 0.7771 - val_auc: 0.8295 - val_loss: 0.5055 - val_precision: 0.8548 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7178 - auc: 0.7857 - loss: 0.5526 - precision: 0.7685 - recall: 0.6590 - val_accuracy: 0.7771 - val_auc: 0.8294 - val_loss: 0.5055 - val_precision: 0.8548 - val_recall: 0.6709 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6916 - auc: 0.7707 - loss: 0.5755 - precision: 0.7209 - recall: 0.6284 - val_accuracy: 0.7771 - val_auc: 0.8294 - val_loss: 0.5055 - val_precision: 0.8548 - val_recall: 0.6709 - learning_rate: 2.0000e-07\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 13.12 GB\n",
            "Fold 17 Validation Accuracy: 0.7771\n",
            "Fold 17 Validation AUC: 0.8296\n",
            "Fold 17 Validation Precision: 0.8548\n",
            "Fold 17 Validation Recall: 0.6709\n",
            "Current memory usage: 13.12 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 13.12 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [04:12<00:00,  1.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [11, 27, 39, 49, 91, 118, 125, 126, 127]\n",
            "Current memory usage: 12.95 GB\n",
            "Current memory usage: 12.96 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [11]\n",
            "Current memory usage: 12.96 GB\n",
            "Current memory usage: 12.96 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [11, 27, 39, 49, 91]\n",
            "Current memory usage: 12.96 GB\n",
            "Current memory usage: 12.96 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [11, 27, 39, 49, 91, 118, 125, 126, 127, 0]\n",
            "Current memory usage: 12.96 GB\n",
            "Current memory usage: 12.96 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [11, 27, 39, 49, 91, 118, 125, 126, 127, 0, 2, 4, 5, 6, 8]\n",
            "Current memory usage: 12.96 GB\n",
            "Current memory usage: 12.96 GB\n",
            "Completed Fold 17.\n",
            "\n",
            "Current memory usage: 12.96 GB\n",
            "Starting Fold 18/25\n",
            "Current memory usage: 12.96 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 12.96 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 12.98 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.5927 - auc: 0.6109 - loss: 0.7450 - precision: 0.5933 - recall: 0.6546 - val_accuracy: 0.6497 - val_auc: 0.7455 - val_loss: 0.5940 - val_precision: 0.6429 - val_recall: 0.6835\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7052 - auc: 0.7948 - loss: 0.5583 - precision: 0.7019 - recall: 0.7697 - val_accuracy: 0.6561 - val_auc: 0.7691 - val_loss: 0.6858 - val_precision: 0.9630 - val_recall: 0.3291\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6876 - auc: 0.7677 - loss: 0.5874 - precision: 0.7321 - recall: 0.6640 - val_accuracy: 0.7197 - val_auc: 0.8143 - val_loss: 0.5285 - val_precision: 0.8571 - val_recall: 0.5316\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7234 - auc: 0.8147 - loss: 0.5209 - precision: 0.7350 - recall: 0.6955 - val_accuracy: 0.7006 - val_auc: 0.7639 - val_loss: 0.6142 - val_precision: 0.9000 - val_recall: 0.4557\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7071 - auc: 0.7890 - loss: 0.5506 - precision: 0.7222 - recall: 0.6435 - val_accuracy: 0.7006 - val_auc: 0.8113 - val_loss: 0.5579 - val_precision: 0.8636 - val_recall: 0.4810\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7266 - auc: 0.7990 - loss: 0.5466 - precision: 0.7437 - recall: 0.7203 - val_accuracy: 0.7197 - val_auc: 0.7890 - val_loss: 0.5491 - val_precision: 0.8182 - val_recall: 0.5696\n",
            "Initial training completed.\n",
            "Current memory usage: 13.39 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 336ms/step - accuracy: 0.7158 - auc: 0.7858 - loss: 0.5609 - precision: 0.7167 - recall: 0.7255 - val_accuracy: 0.7197 - val_auc: 0.8148 - val_loss: 0.5286 - val_precision: 0.8571 - val_recall: 0.5316 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7163 - auc: 0.7735 - loss: 0.5540 - precision: 0.7488 - recall: 0.6307 - val_accuracy: 0.7197 - val_auc: 0.8149 - val_loss: 0.5288 - val_precision: 0.8571 - val_recall: 0.5316 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7178 - auc: 0.7892 - loss: 0.5832 - precision: 0.7418 - recall: 0.7126 - val_accuracy: 0.7197 - val_auc: 0.8147 - val_loss: 0.5290 - val_precision: 0.8571 - val_recall: 0.5316 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 13.59 GB\n",
            "Fold 18 Validation Accuracy: 0.7197\n",
            "Fold 18 Validation AUC: 0.8148\n",
            "Fold 18 Validation Precision: 0.8571\n",
            "Fold 18 Validation Recall: 0.5316\n",
            "Current memory usage: 13.61 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 13.61 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [04:21<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [2, 4, 8, 10, 19, 22, 23, 26, 34, 41, 61, 63, 85, 92, 96, 100, 101, 104, 113, 114]\n",
            "Current memory usage: 13.51 GB\n",
            "Current memory usage: 13.52 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [22]\n",
            "Current memory usage: 13.52 GB\n",
            "Current memory usage: 13.52 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [22, 114, 10, 34, 61]\n",
            "Current memory usage: 13.52 GB\n",
            "Current memory usage: 13.52 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [22, 114, 10, 34, 61, 63, 92, 101, 104, 113]\n",
            "Current memory usage: 13.52 GB\n",
            "Current memory usage: 13.52 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [22, 114, 10, 34, 61, 63, 92, 101, 104, 113, 2, 4, 8, 19, 23]\n",
            "Current memory usage: 13.52 GB\n",
            "Current memory usage: 13.52 GB\n",
            "Completed Fold 18.\n",
            "\n",
            "Current memory usage: 13.52 GB\n",
            "Starting Fold 19/25\n",
            "Current memory usage: 13.52 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 13.52 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 13.53 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 331ms/step - accuracy: 0.5944 - auc: 0.6377 - loss: 0.7233 - precision: 0.5933 - recall: 0.6076 - val_accuracy: 0.6051 - val_auc: 0.7610 - val_loss: 0.6570 - val_precision: 0.7500 - val_recall: 0.3077\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7266 - auc: 0.7869 - loss: 0.5595 - precision: 0.7617 - recall: 0.6853 - val_accuracy: 0.6561 - val_auc: 0.7957 - val_loss: 0.5809 - val_precision: 0.7727 - val_recall: 0.4359\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7529 - auc: 0.8326 - loss: 0.5148 - precision: 0.7489 - recall: 0.7665 - val_accuracy: 0.6306 - val_auc: 0.7909 - val_loss: 0.6656 - val_precision: 0.8125 - val_recall: 0.3333\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7252 - auc: 0.8093 - loss: 0.5318 - precision: 0.7580 - recall: 0.6417 - val_accuracy: 0.7134 - val_auc: 0.7865 - val_loss: 0.5848 - val_precision: 0.8113 - val_recall: 0.5513\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6959 - auc: 0.8004 - loss: 0.5286 - precision: 0.7152 - recall: 0.6773 - val_accuracy: 0.7325 - val_auc: 0.7920 - val_loss: 0.5649 - val_precision: 0.8000 - val_recall: 0.6154\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7270 - auc: 0.8097 - loss: 0.5396 - precision: 0.7683 - recall: 0.6787 - val_accuracy: 0.7006 - val_auc: 0.7883 - val_loss: 0.5926 - val_precision: 0.8163 - val_recall: 0.5128\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7096 - auc: 0.7941 - loss: 0.5365 - precision: 0.7351 - recall: 0.6349 - val_accuracy: 0.7197 - val_auc: 0.7971 - val_loss: 0.5575 - val_precision: 0.7024 - val_recall: 0.7564\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7515 - auc: 0.8313 - loss: 0.5167 - precision: 0.7615 - recall: 0.7334 - val_accuracy: 0.6943 - val_auc: 0.7954 - val_loss: 0.5557 - val_precision: 0.6829 - val_recall: 0.7179\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7633 - auc: 0.8403 - loss: 0.4955 - precision: 0.7797 - recall: 0.7628 - val_accuracy: 0.7261 - val_auc: 0.8030 - val_loss: 0.5568 - val_precision: 0.7612 - val_recall: 0.6538\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7231 - auc: 0.8169 - loss: 0.5308 - precision: 0.7691 - recall: 0.6540 - val_accuracy: 0.7197 - val_auc: 0.7938 - val_loss: 0.5876 - val_precision: 0.8400 - val_recall: 0.5385\n",
            "Initial training completed.\n",
            "Current memory usage: 13.96 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 327ms/step - accuracy: 0.7699 - auc: 0.8509 - loss: 0.4895 - precision: 0.7245 - recall: 0.7851 - val_accuracy: 0.7006 - val_auc: 0.7952 - val_loss: 0.5557 - val_precision: 0.6914 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7165 - auc: 0.8052 - loss: 0.5344 - precision: 0.6856 - recall: 0.7248 - val_accuracy: 0.7006 - val_auc: 0.7952 - val_loss: 0.5557 - val_precision: 0.6914 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7368 - auc: 0.8289 - loss: 0.5063 - precision: 0.7425 - recall: 0.7167 - val_accuracy: 0.7006 - val_auc: 0.7952 - val_loss: 0.5557 - val_precision: 0.6914 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 14.17 GB\n",
            "Fold 19 Validation Accuracy: 0.7006\n",
            "Fold 19 Validation AUC: 0.7952\n",
            "Fold 19 Validation Precision: 0.6914\n",
            "Fold 19 Validation Recall: 0.7179\n",
            "Current memory usage: 14.18 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 14.18 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [04:31<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [4, 10, 47, 61, 66, 70, 85, 98]\n",
            "Current memory usage: 14.08 GB\n",
            "Current memory usage: 14.09 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [4]\n",
            "Current memory usage: 14.09 GB\n",
            "Current memory usage: 14.09 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [4, 47, 10, 61, 66]\n",
            "Current memory usage: 14.09 GB\n",
            "Current memory usage: 14.09 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [4, 47, 10, 61, 66, 70, 85, 98, 0, 1]\n",
            "Current memory usage: 14.09 GB\n",
            "Current memory usage: 14.10 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [4, 47, 10, 61, 66, 70, 85, 98, 0, 1, 2, 5, 6, 7, 11]\n",
            "Current memory usage: 14.10 GB\n",
            "Current memory usage: 14.10 GB\n",
            "Completed Fold 19.\n",
            "\n",
            "Current memory usage: 14.10 GB\n",
            "Starting Fold 20/25\n",
            "Current memory usage: 14.10 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 14.10 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 14.12 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 334ms/step - accuracy: 0.5469 - auc: 0.5812 - loss: 0.8194 - precision: 0.5834 - recall: 0.5799 - val_accuracy: 0.7006 - val_auc: 0.8346 - val_loss: 0.5387 - val_precision: 0.8298 - val_recall: 0.5000\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6745 - auc: 0.7520 - loss: 0.6007 - precision: 0.6527 - recall: 0.6434 - val_accuracy: 0.7452 - val_auc: 0.8215 - val_loss: 0.5374 - val_precision: 0.7436 - val_recall: 0.7436\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6608 - auc: 0.7356 - loss: 0.6096 - precision: 0.6944 - recall: 0.6244 - val_accuracy: 0.7452 - val_auc: 0.8388 - val_loss: 0.5131 - val_precision: 0.7794 - val_recall: 0.6795\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6814 - auc: 0.7667 - loss: 0.5661 - precision: 0.7164 - recall: 0.6800 - val_accuracy: 0.7070 - val_auc: 0.8436 - val_loss: 0.5153 - val_precision: 0.7581 - val_recall: 0.6026\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7152 - auc: 0.7827 - loss: 0.5559 - precision: 0.7263 - recall: 0.7560 - val_accuracy: 0.7580 - val_auc: 0.8544 - val_loss: 0.5031 - val_precision: 0.8030 - val_recall: 0.6795\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7884 - auc: 0.8620 - loss: 0.4815 - precision: 0.8031 - recall: 0.7896 - val_accuracy: 0.6688 - val_auc: 0.8452 - val_loss: 0.5297 - val_precision: 0.8095 - val_recall: 0.4359\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7356 - auc: 0.8177 - loss: 0.5215 - precision: 0.7404 - recall: 0.6896 - val_accuracy: 0.7516 - val_auc: 0.8548 - val_loss: 0.4996 - val_precision: 0.8305 - val_recall: 0.6282\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7323 - auc: 0.8067 - loss: 0.5338 - precision: 0.7428 - recall: 0.6927 - val_accuracy: 0.7134 - val_auc: 0.8460 - val_loss: 0.5271 - val_precision: 0.8667 - val_recall: 0.5000\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6981 - auc: 0.7844 - loss: 0.5523 - precision: 0.7434 - recall: 0.6166 - val_accuracy: 0.7580 - val_auc: 0.8407 - val_loss: 0.4970 - val_precision: 0.7857 - val_recall: 0.7051\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7101 - auc: 0.8174 - loss: 0.5269 - precision: 0.7291 - recall: 0.6748 - val_accuracy: 0.7516 - val_auc: 0.8346 - val_loss: 0.5046 - val_precision: 0.7910 - val_recall: 0.6795\n",
            "Initial training completed.\n",
            "Current memory usage: 14.53 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 338ms/step - accuracy: 0.7171 - auc: 0.7964 - loss: 0.5511 - precision: 0.7418 - recall: 0.6846 - val_accuracy: 0.7580 - val_auc: 0.8406 - val_loss: 0.4969 - val_precision: 0.7857 - val_recall: 0.7051 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7725 - auc: 0.8327 - loss: 0.5121 - precision: 0.7922 - recall: 0.7337 - val_accuracy: 0.7643 - val_auc: 0.8414 - val_loss: 0.4967 - val_precision: 0.7887 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7076 - auc: 0.7893 - loss: 0.5518 - precision: 0.7089 - recall: 0.6334 - val_accuracy: 0.7643 - val_auc: 0.8415 - val_loss: 0.4967 - val_precision: 0.7887 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7171 - auc: 0.8217 - loss: 0.5148 - precision: 0.7319 - recall: 0.6786 - val_accuracy: 0.7643 - val_auc: 0.8409 - val_loss: 0.4966 - val_precision: 0.7887 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7298 - auc: 0.8052 - loss: 0.5360 - precision: 0.7565 - recall: 0.6994 - val_accuracy: 0.7643 - val_auc: 0.8403 - val_loss: 0.4965 - val_precision: 0.7887 - val_recall: 0.7179 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 14.84 GB\n",
            "Fold 20 Validation Accuracy: 0.7643\n",
            "Fold 20 Validation AUC: 0.8403\n",
            "Fold 20 Validation Precision: 0.7887\n",
            "Fold 20 Validation Recall: 0.7179\n",
            "Current memory usage: 14.85 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 14.85 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [04:40<00:00,  2.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [0, 2, 16, 21, 35, 38, 51, 53, 57, 79, 81, 113, 118]\n",
            "Current memory usage: 14.66 GB\n",
            "Current memory usage: 14.67 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [79]\n",
            "Current memory usage: 14.67 GB\n",
            "Current memory usage: 14.67 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [79, 35, 38, 51, 118]\n",
            "Current memory usage: 14.67 GB\n",
            "Current memory usage: 14.67 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [79, 35, 38, 51, 118, 0, 2, 16, 21, 53]\n",
            "Current memory usage: 14.67 GB\n",
            "Current memory usage: 14.67 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [79, 35, 38, 51, 118, 0, 2, 16, 21, 53, 57, 81, 113, 1, 3]\n",
            "Current memory usage: 14.67 GB\n",
            "Current memory usage: 14.67 GB\n",
            "Completed Fold 20.\n",
            "\n",
            "Current memory usage: 14.67 GB\n",
            "Starting Fold 21/25\n",
            "Current memory usage: 14.67 GB\n",
            "Found 628 validated image filenames belonging to 2 classes.\n",
            "Found 158 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 14.67 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 14.69 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 336ms/step - accuracy: 0.6235 - auc: 0.6895 - loss: 0.6909 - precision: 0.6160 - recall: 0.5291 - val_accuracy: 0.7025 - val_auc: 0.7778 - val_loss: 0.5910 - val_precision: 0.6860 - val_recall: 0.7468\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6693 - auc: 0.7354 - loss: 0.6347 - precision: 0.6769 - recall: 0.6717 - val_accuracy: 0.7089 - val_auc: 0.7786 - val_loss: 0.5799 - val_precision: 0.6813 - val_recall: 0.7848\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.6682 - auc: 0.7547 - loss: 0.5837 - precision: 0.6641 - recall: 0.6597 - val_accuracy: 0.7278 - val_auc: 0.7865 - val_loss: 0.5659 - val_precision: 0.7727 - val_recall: 0.6456\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7241 - auc: 0.7856 - loss: 0.5624 - precision: 0.7784 - recall: 0.6362 - val_accuracy: 0.7025 - val_auc: 0.7888 - val_loss: 0.5823 - val_precision: 0.7857 - val_recall: 0.5570\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7437 - auc: 0.7947 - loss: 0.5425 - precision: 0.7706 - recall: 0.6780 - val_accuracy: 0.7152 - val_auc: 0.7781 - val_loss: 0.5883 - val_precision: 0.7179 - val_recall: 0.7089\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7369 - auc: 0.8110 - loss: 0.5434 - precision: 0.7335 - recall: 0.7388 - val_accuracy: 0.7342 - val_auc: 0.7790 - val_loss: 0.6076 - val_precision: 0.7761 - val_recall: 0.6582\n",
            "Initial training completed.\n",
            "Current memory usage: 15.07 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 336ms/step - accuracy: 0.7353 - auc: 0.8236 - loss: 0.5254 - precision: 0.8355 - recall: 0.5948 - val_accuracy: 0.7278 - val_auc: 0.7870 - val_loss: 0.5655 - val_precision: 0.7727 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.6790 - auc: 0.7807 - loss: 0.5782 - precision: 0.7968 - recall: 0.5411 - val_accuracy: 0.7278 - val_auc: 0.7873 - val_loss: 0.5651 - val_precision: 0.7727 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7214 - auc: 0.8229 - loss: 0.5331 - precision: 0.7906 - recall: 0.6116 - val_accuracy: 0.7278 - val_auc: 0.7872 - val_loss: 0.5646 - val_precision: 0.7727 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7773 - auc: 0.8279 - loss: 0.5317 - precision: 0.8699 - recall: 0.6621 - val_accuracy: 0.7278 - val_auc: 0.7881 - val_loss: 0.5643 - val_precision: 0.7727 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6874 - auc: 0.7872 - loss: 0.5577 - precision: 0.7503 - recall: 0.5573 - val_accuracy: 0.7215 - val_auc: 0.7875 - val_loss: 0.5640 - val_precision: 0.7612 - val_recall: 0.6456 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 15.42 GB\n",
            "Fold 21 Validation Accuracy: 0.7215\n",
            "Fold 21 Validation AUC: 0.7875\n",
            "Fold 21 Validation Precision: 0.7612\n",
            "Fold 21 Validation Recall: 0.6456\n",
            "Current memory usage: 15.42 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 15.42 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [04:50<00:00,  2.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [9, 20, 25, 31, 42, 43, 44, 51, 53, 65, 79, 84, 85, 92, 114, 115, 116, 121]\n",
            "Current memory usage: 15.26 GB\n",
            "Current memory usage: 15.22 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [84]\n",
            "Current memory usage: 15.22 GB\n",
            "Current memory usage: 15.23 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [84, 31, 43, 53, 92]\n",
            "Current memory usage: 15.23 GB\n",
            "Current memory usage: 15.23 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [84, 31, 43, 53, 92, 9, 20, 25, 42, 44]\n",
            "Current memory usage: 15.23 GB\n",
            "Current memory usage: 15.23 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [84, 31, 43, 53, 92, 9, 20, 25, 42, 44, 51, 65, 79, 85, 114]\n",
            "Current memory usage: 15.23 GB\n",
            "Current memory usage: 15.23 GB\n",
            "Completed Fold 21.\n",
            "\n",
            "Current memory usage: 15.23 GB\n",
            "Starting Fold 22/25\n",
            "Current memory usage: 15.23 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 15.23 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 15.26 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 333ms/step - accuracy: 0.6146 - auc: 0.6661 - loss: 0.7037 - precision: 0.6096 - recall: 0.5523 - val_accuracy: 0.6879 - val_auc: 0.7858 - val_loss: 0.5798 - val_precision: 0.6389 - val_recall: 0.8734\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.6536 - auc: 0.7523 - loss: 0.6254 - precision: 0.6286 - recall: 0.6503 - val_accuracy: 0.7006 - val_auc: 0.8021 - val_loss: 0.5544 - val_precision: 0.7759 - val_recall: 0.5696\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.6913 - auc: 0.7610 - loss: 0.5996 - precision: 0.7036 - recall: 0.6807 - val_accuracy: 0.6752 - val_auc: 0.7771 - val_loss: 0.5796 - val_precision: 0.7414 - val_recall: 0.5443\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.6814 - auc: 0.7641 - loss: 0.5896 - precision: 0.6871 - recall: 0.6421 - val_accuracy: 0.6943 - val_auc: 0.7722 - val_loss: 0.5668 - val_precision: 0.6962 - val_recall: 0.6962\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7495 - auc: 0.8173 - loss: 0.5324 - precision: 0.7481 - recall: 0.7141 - val_accuracy: 0.6943 - val_auc: 0.7838 - val_loss: 0.5700 - val_precision: 0.7719 - val_recall: 0.5570\n",
            "Initial training completed.\n",
            "Current memory usage: 15.65 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 337ms/step - accuracy: 0.6919 - auc: 0.7687 - loss: 0.5920 - precision: 0.6963 - recall: 0.7041 - val_accuracy: 0.7006 - val_auc: 0.8019 - val_loss: 0.5546 - val_precision: 0.7759 - val_recall: 0.5696 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6843 - auc: 0.7716 - loss: 0.5808 - precision: 0.7054 - recall: 0.6785 - val_accuracy: 0.7006 - val_auc: 0.8022 - val_loss: 0.5548 - val_precision: 0.7759 - val_recall: 0.5696 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6968 - auc: 0.7861 - loss: 0.5544 - precision: 0.6908 - recall: 0.7005 - val_accuracy: 0.7070 - val_auc: 0.8019 - val_loss: 0.5551 - val_precision: 0.7895 - val_recall: 0.5696 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 15.88 GB\n",
            "Fold 22 Validation Accuracy: 0.7006\n",
            "Fold 22 Validation AUC: 0.8019\n",
            "Fold 22 Validation Precision: 0.7759\n",
            "Fold 22 Validation Recall: 0.5696\n",
            "Current memory usage: 15.89 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 15.89 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [05:04<00:00,  2.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [12, 31, 40, 48, 58, 60, 74, 77, 84, 106, 107, 116]\n",
            "Current memory usage: 15.85 GB\n",
            "Current memory usage: 15.80 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [107]\n",
            "Current memory usage: 15.80 GB\n",
            "Current memory usage: 15.80 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [107, 40, 48, 60, 106]\n",
            "Current memory usage: 15.80 GB\n",
            "Current memory usage: 15.81 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [107, 40, 48, 60, 106, 116, 12, 31, 58, 74]\n",
            "Current memory usage: 15.81 GB\n",
            "Current memory usage: 15.81 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [107, 40, 48, 60, 106, 116, 12, 31, 58, 74, 77, 84, 0, 1, 2]\n",
            "Current memory usage: 15.81 GB\n",
            "Current memory usage: 15.81 GB\n",
            "Completed Fold 22.\n",
            "\n",
            "Current memory usage: 15.81 GB\n",
            "Starting Fold 23/25\n",
            "Current memory usage: 15.81 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 15.81 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 15.83 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 336ms/step - accuracy: 0.6007 - auc: 0.5819 - loss: 0.7621 - precision: 0.6167 - recall: 0.6411 - val_accuracy: 0.7070 - val_auc: 0.8362 - val_loss: 0.5766 - val_precision: 0.8837 - val_recall: 0.4810\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7402 - auc: 0.8030 - loss: 0.5536 - precision: 0.7851 - recall: 0.6621 - val_accuracy: 0.7261 - val_auc: 0.8300 - val_loss: 0.5217 - val_precision: 0.8103 - val_recall: 0.5949\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.6761 - auc: 0.7350 - loss: 0.6057 - precision: 0.6787 - recall: 0.6234 - val_accuracy: 0.7006 - val_auc: 0.8231 - val_loss: 0.5734 - val_precision: 0.8636 - val_recall: 0.4810\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7370 - auc: 0.8198 - loss: 0.5222 - precision: 0.7669 - recall: 0.7072 - val_accuracy: 0.7834 - val_auc: 0.8403 - val_loss: 0.4955 - val_precision: 0.8462 - val_recall: 0.6962\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.7090 - auc: 0.7971 - loss: 0.5522 - precision: 0.7104 - recall: 0.7341 - val_accuracy: 0.7452 - val_auc: 0.8184 - val_loss: 0.5333 - val_precision: 0.8545 - val_recall: 0.5949\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7316 - auc: 0.8205 - loss: 0.5148 - precision: 0.7439 - recall: 0.7020 - val_accuracy: 0.7707 - val_auc: 0.8256 - val_loss: 0.5063 - val_precision: 0.8209 - val_recall: 0.6962\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7373 - auc: 0.7982 - loss: 0.5417 - precision: 0.7569 - recall: 0.6838 - val_accuracy: 0.7771 - val_auc: 0.8402 - val_loss: 0.4949 - val_precision: 0.8235 - val_recall: 0.7089\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7623 - auc: 0.8418 - loss: 0.4877 - precision: 0.7640 - recall: 0.7870 - val_accuracy: 0.7771 - val_auc: 0.8463 - val_loss: 0.4883 - val_precision: 0.7973 - val_recall: 0.7468\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7196 - auc: 0.8272 - loss: 0.5072 - precision: 0.7295 - recall: 0.6709 - val_accuracy: 0.7452 - val_auc: 0.8367 - val_loss: 0.5031 - val_precision: 0.7241 - val_recall: 0.7975\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.6680 - auc: 0.7633 - loss: 0.5659 - precision: 0.6753 - recall: 0.6696 - val_accuracy: 0.7389 - val_auc: 0.8289 - val_loss: 0.5102 - val_precision: 0.7500 - val_recall: 0.7215\n",
            "Initial training completed.\n",
            "Current memory usage: 16.25 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 338ms/step - accuracy: 0.7393 - auc: 0.8449 - loss: 0.4845 - precision: 0.7247 - recall: 0.7953 - val_accuracy: 0.7771 - val_auc: 0.8468 - val_loss: 0.4882 - val_precision: 0.7973 - val_recall: 0.7468 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.7930 - auc: 0.8607 - loss: 0.4801 - precision: 0.7707 - recall: 0.8175 - val_accuracy: 0.7834 - val_auc: 0.8470 - val_loss: 0.4881 - val_precision: 0.8082 - val_recall: 0.7468 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7403 - auc: 0.8487 - loss: 0.4766 - precision: 0.7577 - recall: 0.7443 - val_accuracy: 0.7834 - val_auc: 0.8466 - val_loss: 0.4880 - val_precision: 0.8082 - val_recall: 0.7468 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7568 - auc: 0.8532 - loss: 0.4822 - precision: 0.7340 - recall: 0.8262 - val_accuracy: 0.7834 - val_auc: 0.8462 - val_loss: 0.4880 - val_precision: 0.8082 - val_recall: 0.7468 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7781 - auc: 0.8352 - loss: 0.5082 - precision: 0.7666 - recall: 0.8095 - val_accuracy: 0.7834 - val_auc: 0.8466 - val_loss: 0.4879 - val_precision: 0.8082 - val_recall: 0.7468 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 16.54 GB\n",
            "Fold 23 Validation Accuracy: 0.7834\n",
            "Fold 23 Validation AUC: 0.8466\n",
            "Fold 23 Validation Precision: 0.8082\n",
            "Fold 23 Validation Recall: 0.7468\n",
            "Current memory usage: 16.54 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 16.54 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [05:16<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [4, 16, 43, 71, 84]\n",
            "Current memory usage: 16.41 GB\n",
            "Current memory usage: 16.41 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [16]\n",
            "Current memory usage: 16.41 GB\n",
            "Current memory usage: 16.37 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [16, 71, 4, 43, 84]\n",
            "Current memory usage: 16.37 GB\n",
            "Current memory usage: 16.38 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [16, 71, 4, 43, 84, 0, 1, 2, 3, 5]\n",
            "Current memory usage: 16.38 GB\n",
            "Current memory usage: 16.39 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [16, 71, 4, 43, 84, 0, 1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
            "Current memory usage: 16.39 GB\n",
            "Current memory usage: 16.39 GB\n",
            "Completed Fold 23.\n",
            "\n",
            "Current memory usage: 16.39 GB\n",
            "Starting Fold 24/25\n",
            "Current memory usage: 16.39 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 16.39 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 16.41 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 336ms/step - accuracy: 0.5918 - auc: 0.6242 - loss: 0.7483 - precision: 0.6043 - recall: 0.6084 - val_accuracy: 0.6752 - val_auc: 0.7707 - val_loss: 0.5631 - val_precision: 0.7213 - val_recall: 0.5641\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.6579 - auc: 0.7602 - loss: 0.5910 - precision: 0.6473 - recall: 0.6962 - val_accuracy: 0.7006 - val_auc: 0.7958 - val_loss: 0.5407 - val_precision: 0.7460 - val_recall: 0.6026\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7426 - auc: 0.8148 - loss: 0.5313 - precision: 0.7576 - recall: 0.7096 - val_accuracy: 0.7261 - val_auc: 0.7988 - val_loss: 0.5477 - val_precision: 0.7059 - val_recall: 0.7692\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7676 - auc: 0.8315 - loss: 0.5039 - precision: 0.7931 - recall: 0.7140 - val_accuracy: 0.7006 - val_auc: 0.7988 - val_loss: 0.5592 - val_precision: 0.8444 - val_recall: 0.4872\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7304 - auc: 0.7983 - loss: 0.5476 - precision: 0.7452 - recall: 0.6995 - val_accuracy: 0.7261 - val_auc: 0.7937 - val_loss: 0.5362 - val_precision: 0.7612 - val_recall: 0.6538\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7095 - auc: 0.7996 - loss: 0.5396 - precision: 0.7213 - recall: 0.6567 - val_accuracy: 0.6943 - val_auc: 0.7909 - val_loss: 0.5461 - val_precision: 0.6630 - val_recall: 0.7821\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.7257 - auc: 0.8052 - loss: 0.5307 - precision: 0.7307 - recall: 0.7138 - val_accuracy: 0.7070 - val_auc: 0.7990 - val_loss: 0.5430 - val_precision: 0.7353 - val_recall: 0.6410\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7575 - auc: 0.8273 - loss: 0.5184 - precision: 0.7684 - recall: 0.7384 - val_accuracy: 0.6943 - val_auc: 0.8013 - val_loss: 0.5378 - val_precision: 0.7344 - val_recall: 0.6026\n",
            "Initial training completed.\n",
            "Current memory usage: 16.81 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 337ms/step - accuracy: 0.7466 - auc: 0.8084 - loss: 0.5433 - precision: 0.8251 - recall: 0.6226 - val_accuracy: 0.7261 - val_auc: 0.7937 - val_loss: 0.5360 - val_precision: 0.7612 - val_recall: 0.6538 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7399 - auc: 0.8338 - loss: 0.5086 - precision: 0.7969 - recall: 0.6279 - val_accuracy: 0.7197 - val_auc: 0.7943 - val_loss: 0.5359 - val_precision: 0.7500 - val_recall: 0.6538 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7215 - auc: 0.7963 - loss: 0.5493 - precision: 0.7683 - recall: 0.6429 - val_accuracy: 0.7197 - val_auc: 0.7943 - val_loss: 0.5357 - val_precision: 0.7500 - val_recall: 0.6538 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7516 - auc: 0.8357 - loss: 0.5235 - precision: 0.8268 - recall: 0.6534 - val_accuracy: 0.7197 - val_auc: 0.7942 - val_loss: 0.5356 - val_precision: 0.7500 - val_recall: 0.6538 - learning_rate: 1.0000e-06\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7640 - auc: 0.8273 - loss: 0.5147 - precision: 0.8205 - recall: 0.6508 - val_accuracy: 0.7197 - val_auc: 0.7936 - val_loss: 0.5355 - val_precision: 0.7500 - val_recall: 0.6538 - learning_rate: 1.0000e-06\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 17.12 GB\n",
            "Fold 24 Validation Accuracy: 0.7197\n",
            "Fold 24 Validation AUC: 0.7936\n",
            "Fold 24 Validation Precision: 0.7500\n",
            "Fold 24 Validation Recall: 0.6538\n",
            "Current memory usage: 17.12 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 17.12 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [05:25<00:00,  2.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [20, 27, 31, 58, 85, 109, 126]\n",
            "Current memory usage: 16.99 GB\n",
            "Current memory usage: 16.99 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [20]\n",
            "Current memory usage: 16.99 GB\n",
            "Current memory usage: 16.90 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [20, 109, 27, 31, 126]\n",
            "Current memory usage: 16.90 GB\n",
            "Current memory usage: 16.93 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [20, 109, 27, 31, 126, 58, 85, 0, 1, 2]\n",
            "Current memory usage: 16.93 GB\n",
            "Current memory usage: 16.94 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [20, 109, 27, 31, 126, 58, 85, 0, 1, 2, 3, 4, 5, 6, 7]\n",
            "Current memory usage: 16.94 GB\n",
            "Current memory usage: 16.94 GB\n",
            "Completed Fold 24.\n",
            "\n",
            "Current memory usage: 16.94 GB\n",
            "Starting Fold 25/25\n",
            "Current memory usage: 16.94 GB\n",
            "Found 629 validated image filenames belonging to 2 classes.\n",
            "Found 157 validated image filenames belonging to 2 classes.\n",
            "Data generators created successfully.\n",
            "Current memory usage: 16.95 GB\n",
            "Model built successfully.\n",
            "Current memory usage: 16.96 GB\n",
            "Starting initial training...\n",
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 349ms/step - accuracy: 0.5501 - auc: 0.5693 - loss: 0.7931 - precision: 0.5390 - recall: 0.5435 - val_accuracy: 0.6115 - val_auc: 0.8052 - val_loss: 0.6472 - val_precision: 0.8400 - val_recall: 0.2692\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.6810 - auc: 0.7236 - loss: 0.6243 - precision: 0.7132 - recall: 0.5710 - val_accuracy: 0.6688 - val_auc: 0.7995 - val_loss: 0.5910 - val_precision: 0.8095 - val_recall: 0.4359\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.6882 - auc: 0.7510 - loss: 0.5904 - precision: 0.7166 - recall: 0.6259 - val_accuracy: 0.6561 - val_auc: 0.8153 - val_loss: 0.5686 - val_precision: 0.7727 - val_recall: 0.4359\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7213 - auc: 0.7847 - loss: 0.5654 - precision: 0.7550 - recall: 0.7056 - val_accuracy: 0.7070 - val_auc: 0.8099 - val_loss: 0.5560 - val_precision: 0.8077 - val_recall: 0.5385\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.7004 - auc: 0.8056 - loss: 0.5441 - precision: 0.7436 - recall: 0.6656 - val_accuracy: 0.7197 - val_auc: 0.8157 - val_loss: 0.5548 - val_precision: 0.8269 - val_recall: 0.5513\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7202 - auc: 0.8045 - loss: 0.5376 - precision: 0.7248 - recall: 0.6768 - val_accuracy: 0.7516 - val_auc: 0.8184 - val_loss: 0.5366 - val_precision: 0.7241 - val_recall: 0.8077\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7373 - auc: 0.8085 - loss: 0.5425 - precision: 0.7264 - recall: 0.7655 - val_accuracy: 0.7325 - val_auc: 0.8330 - val_loss: 0.5109 - val_precision: 0.7500 - val_recall: 0.6923\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7132 - auc: 0.8102 - loss: 0.5260 - precision: 0.7264 - recall: 0.7348 - val_accuracy: 0.7261 - val_auc: 0.8397 - val_loss: 0.5235 - val_precision: 0.8182 - val_recall: 0.5769\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7019 - auc: 0.7826 - loss: 0.5742 - precision: 0.7076 - recall: 0.6908 - val_accuracy: 0.7516 - val_auc: 0.8224 - val_loss: 0.5248 - val_precision: 0.8095 - val_recall: 0.6538\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7633 - auc: 0.8357 - loss: 0.4955 - precision: 0.7696 - recall: 0.7600 - val_accuracy: 0.7452 - val_auc: 0.8269 - val_loss: 0.5301 - val_precision: 0.8167 - val_recall: 0.6282\n",
            "Initial training completed.\n",
            "Current memory usage: 17.37 GB\n",
            "Starting fine-tuning...\n",
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 339ms/step - accuracy: 0.7266 - auc: 0.8134 - loss: 0.5501 - precision: 0.6902 - recall: 0.8469 - val_accuracy: 0.7325 - val_auc: 0.8328 - val_loss: 0.5108 - val_precision: 0.7500 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7453 - auc: 0.8356 - loss: 0.5108 - precision: 0.7139 - recall: 0.8266 - val_accuracy: 0.7325 - val_auc: 0.8332 - val_loss: 0.5107 - val_precision: 0.7500 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.7717 - auc: 0.8453 - loss: 0.5125 - precision: 0.7408 - recall: 0.8525 - val_accuracy: 0.7325 - val_auc: 0.8331 - val_loss: 0.5107 - val_precision: 0.7500 - val_recall: 0.6923 - learning_rate: 1.0000e-06\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.7399 - auc: 0.8193 - loss: 0.5469 - precision: 0.6994 - recall: 0.8527 - val_accuracy: 0.7389 - val_auc: 0.8331 - val_loss: 0.5107 - val_precision: 0.7606 - val_recall: 0.6923 - learning_rate: 2.0000e-07\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7045 - auc: 0.8173 - loss: 0.5460 - precision: 0.6532 - recall: 0.7856 - val_accuracy: 0.7389 - val_auc: 0.8333 - val_loss: 0.5107 - val_precision: 0.7606 - val_recall: 0.6923 - learning_rate: 2.0000e-07\n",
            "Fine-tuning completed.\n",
            "Current memory usage: 17.69 GB\n",
            "Fold 25 Validation Accuracy: 0.7389\n",
            "Fold 25 Validation AUC: 0.8333\n",
            "Fold 25 Validation Precision: 0.7606\n",
            "Fold 25 Validation Recall: 0.6923\n",
            "Current memory usage: 17.71 GB\n",
            "Number of nodes in the first Dense layer: 128\n",
            "Current memory usage: 17.71 GB\n",
            "Starting node-dropping analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Node Pruning: 100%|██████████| 128/128 [05:35<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes to remove for improved Recall: [2, 6, 26, 75, 82, 83, 86, 88, 93, 98, 100, 109, 116, 117, 124]\n",
            "Current memory usage: 17.55 GB\n",
            "Current memory usage: 17.55 GB\n",
            "Top 1 nodes to prune based on Recall improvement: [6]\n",
            "Current memory usage: 17.55 GB\n",
            "Current memory usage: 17.55 GB\n",
            "Top 5 nodes to prune based on Recall improvement: [6, 88, 2, 26, 75]\n",
            "Current memory usage: 17.55 GB\n",
            "Current memory usage: 17.50 GB\n",
            "Top 10 nodes to prune based on Recall improvement: [6, 88, 2, 26, 75, 82, 83, 86, 93, 98]\n",
            "Current memory usage: 17.50 GB\n",
            "Current memory usage: 17.51 GB\n",
            "Top 15 nodes to prune based on Recall improvement: [6, 88, 2, 26, 75, 82, 83, 86, 93, 98, 100, 109, 116, 117, 124]\n",
            "Current memory usage: 17.51 GB\n",
            "Current memory usage: 17.51 GB\n",
            "Completed Fold 25.\n",
            "\n",
            "Current memory usage: 17.51 GB\n",
            "All performance metrics have been saved to '/content/performance_metrics.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Testing & Analysis of Results"
      ],
      "metadata": {
        "id": "KszGqw52ertk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregating Results for Statistical Testing"
      ],
      "metadata": {
        "id": "eK6rSDA8fJC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# List of pruning strategies including Baseline\n",
        "pruning_strategies = ['Baseline', 'Pruned_All', 'Pruned_Top1', 'Pruned_Top5', 'Pruned_Top10', 'Pruned_Top15']\n",
        "\n",
        "# Initialize a DataFrame to store aggregated metrics\n",
        "aggregated_metrics = results_df.groupby('Pruning_Strategy').agg({\n",
        "    'Accuracy': ['mean', 'std'],\n",
        "    'AUC': ['mean', 'std'],\n",
        "    'Precision': ['mean', 'std'],\n",
        "    'Recall': ['mean', 'std']\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten the MultiIndex columns\n",
        "aggregated_metrics.columns = ['Pruning_Strategy',\n",
        "                              'Accuracy_Mean', 'Accuracy_STD',\n",
        "                              'AUC_Mean', 'AUC_STD',\n",
        "                              'Precision_Mean', 'Precision_STD',\n",
        "                              'Recall_Mean', 'Recall_STD']\n",
        "\n",
        "# Display the aggregated metrics\n",
        "print('\\n=== Aggregated Performance Metrics ===')\n",
        "print(aggregated_metrics)"
      ],
      "metadata": {
        "id": "xIeQFqNCfK8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd3f221-a081-4207-d129-5b04443d6393"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Aggregated Performance Metrics ===\n",
            "  Pruning_Strategy  Accuracy_Mean  Accuracy_STD  AUC_Mean   AUC_STD  \\\n",
            "0         Baseline       0.732333      0.028750  0.813106  0.028185   \n",
            "1       Pruned_All       0.623697      0.084680  0.802808  0.029644   \n",
            "2      Pruned_Top1       0.735896      0.029623  0.811904  0.028516   \n",
            "3     Pruned_Top10       0.682467      0.045704  0.810717  0.029216   \n",
            "4     Pruned_Top15       0.637707      0.075146  0.806082  0.028215   \n",
            "5      Pruned_Top5       0.719102      0.036152  0.811323  0.028530   \n",
            "\n",
            "   Precision_Mean  Precision_STD  Recall_Mean  Recall_STD  \n",
            "0        0.779770       0.048428     0.654047    0.058530  \n",
            "1        0.595009       0.084355     0.916741    0.095286  \n",
            "2        0.759122       0.046238     0.697838    0.055665  \n",
            "3        0.639662       0.062164     0.882116    0.080172  \n",
            "4        0.603628       0.077526     0.910114    0.088356  \n",
            "5        0.695792       0.052861     0.798708    0.075393  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Pruning Analysis"
      ],
      "metadata": {
        "id": "vxo7VYAPZ1Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# 1. Verify Observations per Pruning Strategy\n",
        "# -------------------\n",
        "\n",
        "#List of pruning strategies\n",
        "pruning_strategies = ['Baseline', 'Pruned_All', 'Pruned_Top1', 'Pruned_Top5', 'Pruned_Top10', 'Pruned_Top15']\n",
        "\n",
        "# Verify that each pruning strategy has the same number of observations\n",
        "for strategy in pruning_strategies:\n",
        "    count = results_df[results_df['Pruning_Strategy'] == strategy].shape[0]\n",
        "    print(f\"{strategy} has {count} observations.\")\n",
        "\n",
        "# -------------------\n",
        "# 2. Statistical Tests and Effect Size Calculation\n",
        "# -------------------\n",
        "\n",
        "# Define a function to perform statistical tests and calculate Cohen's d\n",
        "def perform_statistical_analysis(baseline, pruned, strategy_name, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs Shapiro-Wilk test for normality, followed by Paired t-test or Wilcoxon test.\n",
        "    Calculates Cohen's d.\n",
        "    Prints the results and interpretation.\n",
        "    \"\"\"\n",
        "    differences = pruned - baseline\n",
        "    shapiro_stat, shapiro_p = stats.shapiro(differences)\n",
        "    print(f\"\\n--- {strategy_name} ---\")\n",
        "    print(f\"Shapiro-Wilk Test: statistic = {shapiro_stat:.4f}, p-value = {shapiro_p:.4f}\")\n",
        "\n",
        "    if shapiro_p > alpha:\n",
        "        # Data is normally distributed; use Paired t-test\n",
        "        t_stat, p_value = stats.ttest_rel(pruned, baseline)\n",
        "        test_used = \"Paired t-test\"\n",
        "    else:\n",
        "        # Data is not normally distributed; use Wilcoxon Signed-Rank Test\n",
        "        t_stat, p_value = stats.wilcoxon(pruned, baseline)\n",
        "        test_used = \"Wilcoxon Signed-Rank Test\"\n",
        "\n",
        "    print(f\"{test_used}: statistic = {t_stat:.4f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        print(\"Result: Statistically significant difference.\")\n",
        "    else:\n",
        "        print(\"Result: No statistically significant difference.\")\n",
        "\n",
        "    # Calculate Cohen's d for effect size\n",
        "    mean_diff = np.mean(differences)\n",
        "    std_diff = np.std(differences, ddof=1)\n",
        "    cohen_d = mean_diff / std_diff if std_diff != 0 else np.inf\n",
        "    print(f\"Cohen's d: {cohen_d:.4f}\")\n",
        "\n",
        "# Extract baseline Recall scores\n",
        "baseline_recall = results_df[results_df['Pruning_Strategy'] == 'Baseline']['Recall'].values\n",
        "\n",
        "# List of pruning strategies excluding Baseline\n",
        "pruning_strategies_to_test = ['Pruned_All', 'Pruned_Top1', 'Pruned_Top5', 'Pruned_Top10', 'Pruned_Top15']\n",
        "\n",
        "# Number of tests (number of strategies * number of metrics)\n",
        "num_strategies = len(pruning_strategies_to_test)\n",
        "num_metrics = 1  # We are testing Recall; adjust if testing more metrics\n",
        "num_tests = num_strategies * num_metrics\n",
        "\n",
        "# Adjusted alpha using Bonferroni correction\n",
        "alpha_bonferroni = 0.05 / num_tests\n",
        "print(f\"\\nAdjusted alpha after Bonferroni correction: {alpha_bonferroni:.6f}\")\n",
        "\n",
        "# Perform statistical analysis for each pruning strategy\n",
        "for strategy in pruning_strategies_to_test:\n",
        "    # Extract pruned Recall scores\n",
        "    pruned_recall = results_df[results_df['Pruning_Strategy'] == strategy]['Recall'].values\n",
        "\n",
        "    # Perform statistical test with adjusted alpha\n",
        "    perform_statistical_analysis(baseline_recall, pruned_recall, strategy.replace('_', ' ').title(), alpha=alpha_bonferroni)\n",
        "\n",
        "# -------------------\n",
        "# 3. Visualization\n",
        "# -------------------\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# --- Bar Plot of Average Recall with Error Bars ---\n",
        "\n",
        "# Prepare data\n",
        "x = np.arange(len(aggregated_metrics))\n",
        "y = aggregated_metrics['Recall_Mean']\n",
        "yerr = aggregated_metrics['Recall_STD']\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, y, yerr=yerr, capsize=5, color=sns.color_palette(\"muted\"))\n",
        "\n",
        "# Set x-ticks labels\n",
        "plt.xticks(x, aggregated_metrics['Pruning_Strategy'])\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Average Recall Across Pruning Strategies')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Pruning Strategy')\n",
        "\n",
        "# Adjust y-axis limits if necessary\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Annotate the bars with the mean values\n",
        "for index, (mean, std) in enumerate(zip(y, yerr)):\n",
        "    plt.text(index, mean + 0.02, f\"{mean:.2f}\", ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Box Plot of Recall Distribution ---\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.boxplot(x='Pruning_Strategy', y='Recall', data=results_df, palette=\"Set3\")\n",
        "sns.swarmplot(x='Pruning_Strategy', y='Recall', data=results_df, color=\".25\")\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Recall Distribution Across Pruning Strategies')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Pruning Strategy')\n",
        "\n",
        "# Adjust y-axis limits if necessary\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Scatter Plot of Precision vs Recall ---\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Precision', y='Recall', hue='Pruning_Strategy',\n",
        "                style='Pruning_Strategy', data=results_df, palette=\"deep\")\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Precision vs. Recall Across Pruning Strategies')\n",
        "plt.xlabel('Precision')\n",
        "plt.ylabel('Recall')\n",
        "\n",
        "# Adjust axis limits if necessary\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.legend(title='Pruning Strategy', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Save Bar Chart as Image ---\n",
        "\n",
        "# Prepare data\n",
        "x = np.arange(len(aggregated_metrics))\n",
        "y = aggregated_metrics['Recall_Mean']\n",
        "yerr = aggregated_metrics['Recall_STD']\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, y, yerr=yerr, capsize=5, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Set x-ticks labels\n",
        "plt.xticks(x, aggregated_metrics['Pruning_Strategy'])\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Average Recall Across Pruning Strategies')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Pruning Strategy')\n",
        "\n",
        "# Adjust y-axis limits if necessary\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Annotate the bars with the mean values\n",
        "for index, (mean, std) in enumerate(zip(y, yerr)):\n",
        "    plt.text(index, mean + 0.02, f\"{mean:.2f}\", ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "# Save the figure\n",
        "plt.savefig('bar_chart_recall.png')\n",
        "plt.close()\n",
        "print(\"Bar chart saved to 'bar_chart_recall.png'.\")"
      ],
      "metadata": {
        "id": "FeOfimnS1443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d104db2-d825-4bd3-dd0c-a0ac04c1c9a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline has 25 observations.\n",
            "Pruned_All has 25 observations.\n",
            "Pruned_Top1 has 25 observations.\n",
            "Pruned_Top5 has 25 observations.\n",
            "Pruned_Top10 has 25 observations.\n",
            "Pruned_Top15 has 25 observations.\n",
            "\n",
            "Adjusted alpha after Bonferroni correction: 0.010000\n",
            "\n",
            "--- Pruned All ---\n",
            "Shapiro-Wilk Test: statistic = 0.9684, p-value = 0.6050\n",
            "Paired t-test: statistic = 11.9406, p-value = 0.000000\n",
            "Result: Statistically significant difference.\n",
            "Cohen's d: 2.3881\n",
            "\n",
            "--- Pruned Top1 ---\n",
            "Shapiro-Wilk Test: statistic = 0.9164, p-value = 0.0424\n",
            "Paired t-test: statistic = 11.2414, p-value = 0.000000\n",
            "Result: Statistically significant difference.\n",
            "Cohen's d: 2.2483\n",
            "\n",
            "--- Pruned Top5 ---\n",
            "Shapiro-Wilk Test: statistic = 0.9717, p-value = 0.6892\n",
            "Paired t-test: statistic = 11.1339, p-value = 0.000000\n",
            "Result: Statistically significant difference.\n",
            "Cohen's d: 2.2268\n",
            "\n",
            "--- Pruned Top10 ---\n",
            "Shapiro-Wilk Test: statistic = 0.9505, p-value = 0.2567\n",
            "Paired t-test: statistic = 12.4798, p-value = 0.000000\n",
            "Result: Statistically significant difference.\n",
            "Cohen's d: 2.4960\n",
            "\n",
            "--- Pruned Top15 ---\n",
            "Shapiro-Wilk Test: statistic = 0.9630, p-value = 0.4769\n",
            "Paired t-test: statistic = 12.7074, p-value = 0.000000\n",
            "Result: Statistically significant difference.\n",
            "Cohen's d: 2.5415\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-6d998a092ce3>:114: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x='Pruning_Strategy', y='Recall', data=results_df, palette=\"Set3\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bar chart saved to 'bar_chart_recall.png'.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}